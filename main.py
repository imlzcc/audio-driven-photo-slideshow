"""
Audio-Driven Photo Slideshow Generator
éŸ³é¢‘é©±åŠ¨çš„å›¾ç‰‡å¹»ç¯ç‰‡ç”Ÿæˆå™¨
"""

import sys
import os
import random
import time
import shutil
import subprocess
from typing import List, Optional
from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout, 
                             QHBoxLayout, QLabel, QPushButton, QFileDialog, 
                             QMessageBox, QDoubleSpinBox, QComboBox, QProgressBar, QCheckBox,
                             QGroupBox, QFrame, QTextEdit, QSplitter)
from PyQt5.QtCore import Qt, QThread, pyqtSignal, QTimer
from PyQt5.QtGui import QFont
from moviepy.editor import ImageClip, AudioFileClip, concatenate_videoclips
from animation_effects import create_animated_clip, get_supported_effects
from config_manager import ConfigManager
import psutil


class SilentLogger:
    """A simple silent logger that produces no output.
    Safe for GUI apps where sys.stdout may be None.
    """
    def __call__(self, message=None):
        pass
    
    def __getattr__(self, name):
        return lambda *args, **kwargs: None


def safe_write_videofile(video_clip, output_path, fps=24, preset='ultrafast', crf=23, threads=1, audio_codec='aac'):
    """ä½¿ç”¨GPUåŠ é€Ÿ + å¤šçº¿ç¨‹å¸§é¢„å–çš„è¶…é«˜é€Ÿå¯¼å‡º
    
    ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè·å–å¸§ï¼Œé…åˆNVIDIA NVENCç¡¬ä»¶ç¼–ç å™¨
    """
    import tempfile
    import uuid
    import numpy as np
    from concurrent.futures import ThreadPoolExecutor, as_completed
    from queue import Queue
    import threading
    
    temp_dir = tempfile.gettempdir()
    unique_id = uuid.uuid4().hex[:8]
    temp_audio = os.path.join(temp_dir, f"temp_a_{unique_id}.wav")
    temp_video_no_audio = os.path.join(temp_dir, f"temp_v_{unique_id}.mp4")
    
    try:
        # è·å–è§†é¢‘å°ºå¯¸å’Œæ—¶é•¿
        duration = video_clip.duration
        height, width = video_clip.size[1], video_clip.size[0]
        total_frames = int(duration * fps)
        
        # æ­¥éª¤1: ä½¿ç”¨NVENC GPUç¼–ç å™¨é€šè¿‡ç®¡é“æµå¼ç¼–ç è§†é¢‘
        ffmpeg_cmd = [
            'ffmpeg',
            '-y',
            '-f', 'rawvideo',
            '-vcodec', 'rawvideo',
            '-s', f'{width}x{height}',
            '-pix_fmt', 'rgb24',
            '-r', str(fps),
            '-i', '-',  # ä»stdinè¯»å–
            '-c:v', 'h264_nvenc',  # NVIDIA GPUç¼–ç å™¨
            '-preset', 'p1',  # p1æ˜¯æœ€å¿«çš„é¢„è®¾
            '-tune', 'hq',  # é«˜è´¨é‡è°ƒä¼˜
            '-rc', 'vbr',  # å¯å˜æ¯”ç‰¹ç‡
            '-cq', str(crf),
            '-b:v', '8M',  # æé«˜æ¯”ç‰¹ç‡ä»¥æå‡è´¨é‡
            '-maxrate', '15M',
            '-bufsize', '15M',
            '-pix_fmt', 'yuv420p',
            '-loglevel', 'error',
            temp_video_no_audio
        ]
        
        # å¯åŠ¨ffmpegè¿›ç¨‹
        process = subprocess.Popen(
            ffmpeg_cmd,
            stdin=subprocess.PIPE,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL
        )
        
        # ä½¿ç”¨æ‰¹é‡æ¸²æŸ“æ¨¡å¼ - ä¸€æ¬¡æ€§æ¸²æŸ“å¤šå¸§
        batch_size = 60  # æ¯æ‰¹å¤„ç†60å¸§ï¼ˆçº¦2.5ç§’ï¼‰
        
        for batch_start in range(0, total_frames, batch_size):
            batch_end = min(batch_start + batch_size, total_frames)
            
            # æ‰¹é‡è·å–æ—¶é—´ç‚¹
            times = [frame_idx / fps for frame_idx in range(batch_start, batch_end)]
            
            # æ‰¹é‡æ¸²æŸ“å¸§ï¼ˆè¿™æ¯”é€å¸§è°ƒç”¨get_frameå¿«å¾ˆå¤šï¼‰
            for t in times:
                if t >= duration:
                    break
                    
                frame = video_clip.get_frame(t)
                try:
                    process.stdin.write(frame.astype('uint8').tobytes())
                except BrokenPipeError:
                    break
        
        # å…³é—­stdinå¹¶ç­‰å¾…å®Œæˆ
        process.stdin.close()
        process.wait()
        
        # æ­¥éª¤2: å¤„ç†éŸ³é¢‘ - ä½¿ç”¨ffmpegç›´æ¥æå–å’Œåˆå¹¶ï¼Œé¿å…numpyå…¼å®¹æ€§é—®é¢˜
        if video_clip.audio is not None:
            try:
                # ä½¿ç”¨moviepyå†™å…¥ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨write_audiofileé¿å…to_soundarrayçš„numpyé—®é¢˜
                print(f"DEBUG: ä½¿ç”¨moviepyå¯¼å‡ºéŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶...")
                video_clip.audio.write_audiofile(
                    temp_audio,
                    fps=44100,
                    nbytes=2,
                    codec='pcm_s16le',
                    logger=None,
                    verbose=False
                )
                
                # éªŒè¯éŸ³é¢‘æ–‡ä»¶æ˜¯å¦åˆ›å»ºæˆåŠŸ
                if not os.path.exists(temp_audio) or os.path.getsize(temp_audio) == 0:
                    raise Exception("éŸ³é¢‘æ–‡ä»¶åˆ›å»ºå¤±è´¥")
                
                print(f"DEBUG: éŸ³é¢‘æ–‡ä»¶å·²åˆ›å»º: {temp_audio}")
                
                # ä½¿ç”¨ffmpegåˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘
                cmd = [
                    'ffmpeg', '-y',
                    '-i', temp_video_no_audio,
                    '-i', temp_audio,
                    '-c:v', 'copy',  # ç›´æ¥å¤åˆ¶è§†é¢‘æµ
                    '-c:a', 'aac',   # éŸ³é¢‘ç¼–ç ä¸ºAAC
                    '-b:a', '192k',  # éŸ³é¢‘æ¯”ç‰¹ç‡
                    '-shortest',     # ä½¿ç”¨æœ€çŸ­çš„æµé•¿åº¦
                    '-movflags', '+faststart',
                    output_path
                ]
                
                print(f"DEBUG: æ‰§è¡Œffmpegåˆå¹¶å‘½ä»¤...")
                # è¿è¡Œffmpegï¼Œæ•è·é”™è¯¯è¾“å‡º
                result = subprocess.run(
                    cmd, 
                    stdout=subprocess.PIPE, 
                    stderr=subprocess.PIPE,
                    check=False
                )
                
                if result.returncode != 0:
                    error_msg = result.stderr.decode('utf-8', errors='ignore')
                    raise Exception(f"ffmpegåˆå¹¶éŸ³é¢‘å¤±è´¥: {error_msg}")
                
                # éªŒè¯è¾“å‡ºæ–‡ä»¶
                if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:
                    raise Exception("è¾“å‡ºæ–‡ä»¶åˆ›å»ºå¤±è´¥")
                
                print(f"DEBUG: è§†é¢‘éŸ³é¢‘åˆå¹¶æˆåŠŸ")
                    
            except Exception as e:
                # å¦‚æœéŸ³é¢‘å¤„ç†å¤±è´¥ï¼Œè‡³å°‘ä¿å­˜æ— éŸ³é¢‘ç‰ˆæœ¬ï¼Œå¹¶æŠ¥å‘Šé”™è¯¯
                import traceback
                print(f"è­¦å‘Š: éŸ³é¢‘å¤„ç†å¤±è´¥ - {str(e)}")
                print(traceback.format_exc())
                
                # ä¿å­˜æ— éŸ³é¢‘ç‰ˆæœ¬
                if os.path.exists(temp_video_no_audio):
                    shutil.copy2(temp_video_no_audio, output_path)
                    raise Exception(f"éŸ³é¢‘å¤„ç†å¤±è´¥ï¼Œå·²ä¿å­˜æ— éŸ³é¢‘ç‰ˆæœ¬: {str(e)}")
                else:
                    raise
        else:
            # æ²¡æœ‰éŸ³é¢‘ï¼Œç›´æ¥å¤åˆ¶
            shutil.copy2(temp_video_no_audio, output_path)
            
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for f in [temp_audio, temp_video_no_audio]:
            if os.path.exists(f):
                try:
                    os.remove(f)
                except:
                    pass


class VideoGenerationWorker(QThread):
    """è§†é¢‘ç”Ÿæˆå·¥ä½œçº¿ç¨‹"""
    
    # ä¿¡å·å®šä¹‰
    progress_updated = pyqtSignal(int)  # è¿›åº¦æ›´æ–° (0-100)
    status_updated = pyqtSignal(str)    # çŠ¶æ€æ›´æ–°
    log_updated = pyqtSignal(str)       # æ—¥å¿—æ›´æ–°
    generation_finished = pyqtSignal(bool, str)  # ç”Ÿæˆå®Œæˆ (æˆåŠŸ/å¤±è´¥, æ¶ˆæ¯)
    
    def __init__(self, image_folder: str, audio_file: str, image_duration: float | tuple, 
                 animation_effect: str, output_path: str, animation_intensity: float = 1.0,
                 resolution: tuple | None = None, fps: int = 24, preset: str = "ultrafast",
                 crf: int = 23, threads: int | None = None, processed_folder: str | None = None,
                 video_clip_folder: str | None = None, enable_video_clips: bool = False, 
                 video_clip_count: int = 3, video_clip_scale_mode: str = "crop",
                 processed_video_folder: str | None = None, enable_segmented_processing: bool = True):
        super().__init__()
        self.image_folder = image_folder
        self.audio_file = audio_file
        self.image_duration = image_duration  # å¯ä¸ºæµ®ç‚¹æ•°æˆ–(min,max)å…ƒç»„
        self.animation_effect = animation_effect
        self.output_path = output_path
        self.animation_intensity = animation_intensity
        self.resolution = resolution
        self.fps = fps
        self.preset = preset
        self.crf = crf
        self.threads = threads if threads and threads > 0 else max(1, (os.cpu_count() or 2) - 1)
        self.processed_folder = processed_folder
        self.video_clip_folder = video_clip_folder
        self.enable_video_clips = enable_video_clips
        self.video_clip_count = video_clip_count
        self.video_clip_scale_mode = video_clip_scale_mode
        self.processed_video_folder = processed_video_folder
        self.enable_segmented_processing = enable_segmented_processing
        
        # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
        self.image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp'}
        
        # æ”¯æŒçš„è§†é¢‘æ ¼å¼
        self.video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm'}
        
        # è·Ÿè¸ªå®é™…å¤„ç†çš„å›¾ç‰‡
        self.actually_processed_images = []
        
        # è·Ÿè¸ªå®é™…å¤„ç†çš„è§†é¢‘ç‰‡æ®µ
        self.actually_processed_videos = []
        
        # åˆ†æ®µå¯¼å‡ºäº§ç”Ÿçš„ä¸´æ—¶æ–‡ä»¶
        self.temp_segment_files = []
        
        # çº¿ç¨‹æ§åˆ¶
        self._is_running = True
    
    def run(self):
        """æ‰§è¡Œè§†é¢‘ç”Ÿæˆ"""
        # å…¨å±€è®¾ç½®stdout/stderrä¿æŠ¤ï¼Œé¿å…moviepyä»»ä½•åœ°æ–¹è®¿é—®Noneçš„stdout
        original_stdout = sys.stdout
        original_stderr = sys.stderr
        original_stdin = sys.stdin
        
        class DummyFile:
            def write(self, x): return len(str(x)) if x else 0
            def flush(self): pass
            def close(self): pass
            def read(self, *args): return ''
            def readline(self, *args): return ''
            def isatty(self): return False
            def fileno(self): return -1
            def __getattr__(self, name): return lambda *args, **kwargs: None
        
        dummy = DummyFile()
        if sys.stdout is None:
            sys.stdout = dummy
        if sys.stderr is None:
            sys.stderr = dummy
        if sys.stdin is None:
            sys.stdin = dummy
        
        try:
            if not self._is_running:
                return
            
            # è®°å½•å¼€å§‹æ—¶é—´
            import time as time_module
            start_time = time_module.time()
            step_times = {}  # è®°å½•å„æ­¥éª¤è€—æ—¶
            
            # æ­¥éª¤1: è¾“å…¥éªŒè¯
            self.log_updated.emit("=== å¼€å§‹è§†é¢‘ç”Ÿæˆ ===")
            self.log_updated.emit(f"å¼€å§‹æ—¶é—´: {time_module.strftime('%Y-%m-%d %H:%M:%S')}")
            self.log_updated.emit(f"å›¾ç‰‡æ–‡ä»¶å¤¹: {self.image_folder}")
            self.log_updated.emit(f"éŸ³é¢‘æ–‡ä»¶: {self.audio_file}")
            if isinstance(self.image_duration, tuple):
                self.log_updated.emit(f"å›¾ç‰‡æ—¶é•¿èŒƒå›´: {self.image_duration[0]} - {self.image_duration[1]} ç§’")
            else:
                self.log_updated.emit(f"å›¾ç‰‡æ—¶é•¿: {self.image_duration}ç§’")
            self.log_updated.emit(f"åŠ¨ç”»æ•ˆæœ: {self.animation_effect}")
            self.log_updated.emit(f"åŠ¨ç”»å¼ºåº¦: {self.animation_intensity}x")
            self.log_updated.emit(f"è¾“å‡ºè·¯å¾„: {self.output_path}")
            if self.resolution:
                self.log_updated.emit(f"ç›®æ ‡åˆ†è¾¨ç‡: {self.resolution[0]}x{self.resolution[1]}")
            self.log_updated.emit(f"å¯¼å‡ºFPS: {self.fps}")
            self.log_updated.emit(f"ç¼–ç é¢„è®¾: {self.preset} | CRF: {self.crf} | çº¿ç¨‹: {self.threads}")
            
            self.status_updated.emit("éªŒè¯è¾“å…¥æ–‡ä»¶...")
            self.log_updated.emit("æ­¥éª¤1: éªŒè¯è¾“å…¥æ–‡ä»¶...")
            self.progress_updated.emit(5)
            
            if not os.path.exists(self.image_folder):
                raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {self.image_folder}")
            
            if not os.path.exists(self.audio_file):
                raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {self.audio_file}")
            
            self.log_updated.emit("âœ“ è¾“å…¥æ–‡ä»¶éªŒè¯é€šè¿‡")
            
            # æ­¥éª¤2: åŠ è½½éŸ³é¢‘æ–‡ä»¶
            step_start = time_module.time()
            self.status_updated.emit("åŠ è½½éŸ³é¢‘æ–‡ä»¶...")
            self.log_updated.emit("æ­¥éª¤2: åŠ è½½éŸ³é¢‘æ–‡ä»¶...")
            self.progress_updated.emit(10)
            
            audio_clip = AudioFileClip(self.audio_file)
            audio_duration = audio_clip.duration
            step_times['åŠ è½½éŸ³é¢‘'] = time_module.time() - step_start
            self.log_updated.emit(f"âœ“ éŸ³é¢‘åŠ è½½å®Œæˆï¼Œæ—¶é•¿: {audio_duration:.2f}ç§’ ({audio_duration/60:.1f}åˆ†é’Ÿ) [è€—æ—¶: {step_times['åŠ è½½éŸ³é¢‘']:.1f}ç§’]")
            
            # æ­¥éª¤3: è¯»å–å›¾ç‰‡æ–‡ä»¶å¤¹
            step_start = time_module.time()
            self.status_updated.emit("æ‰«æå›¾ç‰‡æ–‡ä»¶...")
            self.log_updated.emit("æ­¥éª¤3: æ‰«æå›¾ç‰‡æ–‡ä»¶...")
            self.progress_updated.emit(15)
            
            image_files = []
            for file in os.listdir(self.image_folder):
                if any(file.lower().endswith(ext) for ext in self.image_extensions):
                    image_files.append(os.path.join(self.image_folder, file))
            
            if not image_files:
                raise ValueError("å›¾ç‰‡æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„å›¾ç‰‡æ–‡ä»¶")
            
            # æŒ‰æ–‡ä»¶åæ’åº
            image_files.sort()
            step_times['æ‰«æå›¾ç‰‡'] = time_module.time() - step_start
            self.log_updated.emit(f"âœ“ æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡ [è€—æ—¶: {step_times['æ‰«æå›¾ç‰‡']:.1f}ç§’]")
            self.log_updated.emit(f"å›¾ç‰‡åˆ—è¡¨: {[os.path.basename(f) for f in image_files[:5]]}{'...' if len(image_files) > 5 else ''}")

            # æ­¥éª¤4: åˆ›å»ºè§†é¢‘ç‰‡æ®µ
            step_start = time_module.time()
            self.status_updated.emit("åˆ›å»ºè§†é¢‘ç‰‡æ®µ...")
            self.log_updated.emit("æ­¥éª¤4: åˆ›å»ºè§†é¢‘ç‰‡æ®µ...")
            self.log_updated.emit(f"é¢„è®¡å¤„ç† {len(image_files)} å¼ å›¾ç‰‡ï¼Œæ¯å¼  {self.image_duration} ç§’")
            self.progress_updated.emit(20)
            
            # å¦‚æœå¯ç”¨äº†è§†é¢‘ç‰‡æ®µæ’å…¥ï¼Œéœ€è¦é¢„ç•™æ—¶é—´
            available_duration = audio_duration
            if self.enable_video_clips:
                # ä¼°ç®—è§†é¢‘ç‰‡æ®µéœ€è¦çš„æ€»æ—¶é•¿ï¼ˆå‡è®¾æ¯ä¸ªè§†é¢‘ç‰‡æ®µå¹³å‡8ç§’ï¼‰
                estimated_video_clips_duration = self.video_clip_count * 8.0
                available_duration = audio_duration - estimated_video_clips_duration
                self.log_updated.emit(f"ä¸ºè§†é¢‘ç‰‡æ®µé¢„ç•™æ—¶é—´: {estimated_video_clips_duration:.1f}s, å›¾ç‰‡å¯ç”¨æ—¶é•¿: {available_duration:.1f}s")
            
            clips = []
            current_video_duration = 0.0
            total_images = len(image_files)
            processed_count = 0
            
            for i, image_path in enumerate(image_files):
                # æ£€æŸ¥æ—¶é•¿ä¸Šé™ï¼ˆä½¿ç”¨å¯ç”¨æ—¶é•¿è€Œä¸æ˜¯éŸ³é¢‘æ—¶é•¿ï¼‰
                if current_video_duration >= available_duration:
                    self.log_updated.emit(f"å·²è¾¾åˆ°å›¾ç‰‡å¯ç”¨æ—¶é•¿ä¸Šé™ï¼Œåœæ­¢å¤„ç†å‰©ä½™å›¾ç‰‡")
                    break
                
                # è®¡ç®—å½“å‰ç‰‡æ®µæ—¶é•¿ï¼ˆèŒƒå›´å†…éšæœºï¼‰
                remaining_time = available_duration - current_video_duration
                if isinstance(self.image_duration, tuple):
                    dmin, dmax = self.image_duration
                    rnd = random.random()
                    desired = dmin + (dmax - dmin) * rnd
                else:
                    desired = float(self.image_duration)
                clip_duration = min(desired, remaining_time)
                
                if clip_duration <= 0:
                    self.log_updated.emit(f"å‰©ä½™æ—¶é—´ä¸è¶³ï¼Œåœæ­¢å¤„ç†")
                    break
                
                # æ›´æ–°çŠ¶æ€
                self.status_updated.emit(f"æ­£åœ¨å¤„ç†ç¬¬ {i+1} / {total_images} å¼ å›¾ç‰‡...")
                progress = 20 + (i / total_images) * 60  # 20% åˆ° 80%
                self.progress_updated.emit(int(progress))
                
                try:
                    # é€‰æ‹©åŠ¨ç”»æ•ˆæœ
                    effect = self.animation_effect
                    if effect == "éšæœºæ•ˆæœ":
                        # éšæœºé€‰æ‹©ä¸€ä¸ªæ•ˆæœï¼ˆæ’é™¤"éšæœºæ•ˆæœ"å’Œ"No Animation"ï¼‰
                        available_effects = [e for e in get_supported_effects() 
                                           if e not in ["éšæœºæ•ˆæœ", "No Animation"]]
                        effect = random.choice(available_effects)
                    
                    self.log_updated.emit(f"å¤„ç†å›¾ç‰‡ {i+1}: {os.path.basename(image_path)} (ç›®æ ‡: {desired:.1f}s, å®é™…: {clip_duration:.1f}s, æ•ˆæœ: {effect}, å¼ºåº¦: {self.animation_intensity}x)")
                    
                    # åˆ›å»ºåŠ¨ç”»ç‰‡æ®µ
                    clip = create_animated_clip(
                        image_path,
                        clip_duration,
                        effect,
                        self.animation_intensity,
                        self.resolution
                    )
                    clips.append(clip)
                    
                    # è®°å½•å®é™…å¤„ç†çš„å›¾ç‰‡
                    self.actually_processed_images.append(image_path)
                    
                    current_video_duration += clip_duration
                    processed_count += 1
                    
                    self.log_updated.emit(f"âœ“ å›¾ç‰‡ {i+1} å¤„ç†å®Œæˆï¼Œå½“å‰è§†é¢‘æ—¶é•¿: {current_video_duration:.1f}s")
                    
                except Exception as e:
                    self.log_updated.emit(f"âœ— å¤„ç†å›¾ç‰‡ {i+1} å¤±è´¥: {str(e)}")
                    continue
            
            if not clips:
                raise ValueError("æ²¡æœ‰æˆåŠŸåˆ›å»ºä»»ä½•è§†é¢‘ç‰‡æ®µ")
            
            step_times['åˆ›å»ºè§†é¢‘ç‰‡æ®µ'] = time_module.time() - step_start
            self.log_updated.emit(f"âœ“ è§†é¢‘ç‰‡æ®µåˆ›å»ºå®Œæˆï¼Œå…±å¤„ç† {processed_count} å¼ å›¾ç‰‡ [è€—æ—¶: {step_times['åˆ›å»ºè§†é¢‘ç‰‡æ®µ']:.1f}ç§’]")
            self.log_updated.emit(f"æ€»è§†é¢‘æ—¶é•¿: {current_video_duration:.1f}s")
            
            # æ­¥éª¤5: æ’å…¥è§†é¢‘ç‰‡æ®µ
            if self.enable_video_clips:
                step_start = time_module.time()
                self.status_updated.emit("æ’å…¥è§†é¢‘ç‰‡æ®µ...")
                self.log_updated.emit("æ­¥éª¤5: æ’å…¥è§†é¢‘ç‰‡æ®µ...")
                self.progress_updated.emit(80)
                clips = self.insert_video_clips(clips, audio_duration, image_files)
                
                # é‡æ–°è®¡ç®—è§†é¢‘æ€»æ—¶é•¿
                new_video_duration = sum(clip.duration for clip in clips)
                step_times['æ’å…¥è§†é¢‘ç‰‡æ®µ'] = time_module.time() - step_start
                self.log_updated.emit(f"æ’å…¥è§†é¢‘ç‰‡æ®µåï¼Œæ€»æ—¶é•¿: {new_video_duration:.2f}s [è€—æ—¶: {step_times['æ’å…¥è§†é¢‘ç‰‡æ®µ']:.1f}ç§’]")
                
                # å¦‚æœè§†é¢‘æ—¶é•¿è¶…è¿‡éŸ³é¢‘æ—¶é•¿ï¼Œç»™å‡ºè­¦å‘Š
                if new_video_duration > audio_duration:
                    self.log_updated.emit(f"è­¦å‘Š: æ’å…¥è§†é¢‘ç‰‡æ®µåï¼Œè§†é¢‘æ—¶é•¿({new_video_duration:.2f}s)è¶…è¿‡éŸ³é¢‘æ—¶é•¿({audio_duration:.2f}s)")
                    self.log_updated.emit("ç³»ç»Ÿå°†å¾ªç¯æ’­æ”¾éŸ³é¢‘ä»¥åŒ¹é…è§†é¢‘é•¿åº¦")
                
                self.log_updated.emit("âœ“ è§†é¢‘ç‰‡æ®µæ’å…¥å®Œæˆ")
            
            # æ­¥éª¤6: åˆ†æ®µå¤„ç†æˆ–æœ€ç»ˆè§†é¢‘åˆæˆ
            step_start = time_module.time()
            if self.enable_segmented_processing and audio_duration > 300:  # è¶…è¿‡5åˆ†é’Ÿå¯ç”¨åˆ†æ®µå¤„ç†
                self.status_updated.emit("åˆ†æ®µå¤„ç†è§†é¢‘...")
                self.log_updated.emit("æ­¥éª¤6: åˆ†æ®µå¤„ç†è§†é¢‘...")
                self.progress_updated.emit(85)
                final_video = self.process_segmented_video(clips, audio_clip, audio_duration, image_files)
            else:
                self.status_updated.emit("åˆæˆè§†é¢‘...")
                self.log_updated.emit("æ­¥éª¤6: åˆæˆè§†é¢‘...")
                self.progress_updated.emit(85)
                final_video = self.process_single_video(clips, audio_clip, audio_duration)
            
            # è®¾ç½®éŸ³é¢‘
            final_video = final_video.set_audio(audio_clip)
            self.log_updated.emit(f"âœ“ è§†é¢‘éŸ³é¢‘åŒæ­¥å®Œæˆï¼Œæœ€ç»ˆæ—¶é•¿: {final_video.duration:.2f}s")
            
            # æ­¥éª¤8: å¯¼å‡ºè§†é¢‘
            self.status_updated.emit("å¯¼å‡ºè§†é¢‘ä¸­...")
            self.log_updated.emit("æ­¥éª¤8: å¯¼å‡ºè§†é¢‘...")
            self.log_updated.emit(f"æ­£åœ¨å¯¼å‡ºåˆ°: {self.output_path}")
            self.log_updated.emit("æ³¨æ„: å¯¼å‡ºè¿‡ç¨‹å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
            self.progress_updated.emit(95)
            
            # æ ¹æ®è§†é¢‘é•¿åº¦è°ƒæ•´å¯¼å‡ºå‚æ•°
            self.log_updated.emit("å¼€å§‹ç¼–ç å¯¼å‡º...")
            
            # ä½¿ç”¨å®‰å…¨çš„å¯¼å‡ºå‡½æ•°
            safe_write_videofile(
                final_video,
                self.output_path,
                fps=self.fps,
                preset=self.preset,
                crf=self.crf,
                threads=self.threads,
                audio_codec='aac'
            )
            
            step_times['å¯¼å‡ºè§†é¢‘'] = time_module.time() - step_start
            self.log_updated.emit(f"âœ“ è§†é¢‘å¯¼å‡ºå®Œæˆ [è€—æ—¶: {step_times['å¯¼å‡ºè§†é¢‘']:.1f}ç§’]")
            
            # æ¸…ç†èµ„æº
            self.log_updated.emit("æ­£åœ¨æ¸…ç†èµ„æº...")
            audio_clip.close()
            final_video.close()
            # åˆ é™¤åˆ†æ®µä¸´æ—¶æ–‡ä»¶
            if hasattr(self, 'temp_segment_files') and self.temp_segment_files:
                for fp in self.temp_segment_files:
                    try:
                        if os.path.exists(fp):
                            os.remove(fp)
                    except Exception:
                        pass
            self.log_updated.emit("âœ“ èµ„æºæ¸…ç†å®Œæˆ")
            
            # ç§»åŠ¨å·²å¤„ç†çš„å›¾ç‰‡åˆ°æŒ‡å®šæ–‡ä»¶å¤¹
            if self.processed_folder and os.path.exists(self.processed_folder):
                self.move_processed_images()
            
            # ç§»åŠ¨å·²å¤„ç†çš„è§†é¢‘ç‰‡æ®µåˆ°æŒ‡å®šæ–‡ä»¶å¤¹
            if self.processed_video_folder and os.path.exists(self.processed_video_folder):
                self.move_processed_videos()
            
            # è®¡ç®—æ€»è€—æ—¶
            total_time = time_module.time() - start_time
            
            self.status_updated.emit("å®Œæˆï¼")
            self.progress_updated.emit(100)
            self.log_updated.emit("=== è§†é¢‘ç”Ÿæˆå®Œæˆ ===")
            self.log_updated.emit(f"å®Œæˆæ—¶é—´: {time_module.strftime('%Y-%m-%d %H:%M:%S')}")
            self.log_updated.emit(f"")
            self.log_updated.emit(f"ğŸ“Š è€—æ—¶ç»Ÿè®¡:")
            for step_name, step_time in step_times.items():
                percentage = (step_time / total_time) * 100 if total_time > 0 else 0
                self.log_updated.emit(f"  â€¢ {step_name}: {step_time:.1f}ç§’ ({percentage:.1f}%)")
            self.log_updated.emit(f"")
            self.log_updated.emit(f"â±ï¸ æ€»è€—æ—¶: {total_time:.1f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")
            if audio_duration > 0:
                speed_ratio = audio_duration / total_time
                self.log_updated.emit(f"âš¡ å¤„ç†é€Ÿåº¦: {speed_ratio:.2f}x å®æ—¶é€Ÿåº¦")
            self.generation_finished.emit(True, f"è§†é¢‘å·²æˆåŠŸä¿å­˜åˆ°: {self.output_path}")
            
        except Exception as e:
            self.log_updated.emit(f"âœ— ç”Ÿæˆå¤±è´¥: {str(e)}")
            self.status_updated.emit("ç”Ÿæˆå¤±è´¥")
            self.generation_finished.emit(False, f"ç”Ÿæˆå¤±è´¥: {str(e)}")
        finally:
            # æ¢å¤åŸå§‹çš„stdout/stderr/stdin
            sys.stdout = original_stdout
            sys.stderr = original_stderr
            sys.stdin = original_stdin
    
    def process_single_video(self, clips, audio_clip, audio_duration):
        """å¤„ç†å•ä¸ªè§†é¢‘ï¼ˆéåˆ†æ®µæ¨¡å¼ï¼‰"""
        # æ‹¼æ¥è§†é¢‘ç‰‡æ®µ
        self.log_updated.emit("æ­£åœ¨æ‹¼æ¥è§†é¢‘ç‰‡æ®µ...")
        # å·²ç»Ÿä¸€åˆ†è¾¨ç‡æ—¶ä½¿ç”¨æ›´å¿«çš„ chain æ–¹å¼
        if self.resolution:
            final_video = concatenate_videoclips(clips, method="chain")
        else:
            final_video = concatenate_videoclips(clips)
        final_video_duration = final_video.duration
        self.log_updated.emit(f"âœ“ è§†é¢‘æ‹¼æ¥å®Œæˆï¼Œæœ€ç»ˆæ—¶é•¿: {final_video_duration:.1f}s")
        
        # ç²¾ç¡®åŒæ­¥è§†é¢‘åˆ°éŸ³é¢‘é•¿åº¦
        self.status_updated.emit("åŒæ­¥è§†é¢‘åˆ°éŸ³é¢‘é•¿åº¦...")
        self.log_updated.emit("æ­¥éª¤7: åŒæ­¥è§†é¢‘åˆ°éŸ³é¢‘é•¿åº¦...")
        self.progress_updated.emit(90)
        
        # å°†è§†é¢‘è°ƒæ•´åˆ°ä¸éŸ³é¢‘ç›¸åŒçš„é•¿åº¦
        self.log_updated.emit("æ­£åœ¨åŒæ­¥è§†é¢‘åˆ°éŸ³é¢‘é•¿åº¦...")
        self.log_updated.emit(f"éŸ³é¢‘æ—¶é•¿: {audio_clip.duration:.2f}s, è§†é¢‘æ—¶é•¿: {final_video_duration:.2f}s")
        
        # å¤„ç†éŸ³é¢‘å’Œè§†é¢‘æ—¶é•¿ä¸åŒ¹é…çš„æƒ…å†µ
        if final_video_duration < audio_clip.duration:
            # è§†é¢‘æ¯”éŸ³é¢‘çŸ­ï¼Œéœ€è¦å»¶é•¿è§†é¢‘
            self.log_updated.emit(f"è§†é¢‘æ—¶é•¿({final_video_duration:.2f}s)çŸ­äºéŸ³é¢‘æ—¶é•¿({audio_clip.duration:.2f}s)ï¼Œå°†å»¶é•¿è§†é¢‘")
            
            # è®¡ç®—éœ€è¦å»¶é•¿çš„æ—¶é•¿
            extend_duration = audio_clip.duration - final_video_duration
            self.log_updated.emit(f"éœ€è¦å»¶é•¿è§†é¢‘ {extend_duration:.2f}s")
            
            # ä½¿ç”¨æœ€åä¸€å¸§å»¶é•¿è§†é¢‘
            last_frame = final_video.subclip(final_video_duration - 0.1, final_video_duration)
            extended_clip = last_frame.loop(duration=extend_duration)
            
            # æ‹¼æ¥åŸè§†é¢‘å’Œå»¶é•¿éƒ¨åˆ†
            final_video = concatenate_videoclips([final_video, extended_clip])
            final_video_duration = audio_clip.duration
            self.log_updated.emit(f"âœ“ è§†é¢‘å»¶é•¿å®Œæˆï¼Œæœ€ç»ˆæ—¶é•¿: {final_video_duration:.2f}s")
            
        elif final_video_duration > audio_clip.duration:
            # è§†é¢‘æ¯”éŸ³é¢‘é•¿ï¼Œéœ€è¦ç¼©çŸ­è§†é¢‘
            self.log_updated.emit(f"è§†é¢‘æ—¶é•¿({final_video_duration:.2f}s)è¶…è¿‡éŸ³é¢‘æ—¶é•¿({audio_clip.duration:.2f}s)ï¼Œå°†ç¼©çŸ­è§†é¢‘")
            
            # ç›´æ¥å‰ªè¾‘è§†é¢‘åˆ°éŸ³é¢‘é•¿åº¦
            final_video = final_video.subclip(0, audio_clip.duration)
            final_video_duration = audio_clip.duration
            self.log_updated.emit(f"âœ“ è§†é¢‘ç¼©çŸ­å®Œæˆï¼Œæœ€ç»ˆæ—¶é•¿: {final_video_duration:.2f}s")
        
        return final_video
    
    def process_segmented_video(self, clips, audio_clip, audio_duration, image_files):
        """åˆ†æ®µå¤„ç†è§†é¢‘ï¼ˆèŠ‚çœå†…å­˜ï¼‰"""
        self.log_updated.emit(f"å¼€å§‹åˆ†æ®µå¤„ç†ï¼ŒéŸ³é¢‘æ€»æ—¶é•¿: {audio_duration:.1f}s")
        
        # è®¡ç®—åˆ†æ®µå‚æ•°
        segment_duration = 300  # æ¯æ®µ5åˆ†é’Ÿ
        num_segments = int(audio_duration / segment_duration) + 1
        self.log_updated.emit(f"å°†åˆ†ä¸º {num_segments} æ®µå¤„ç†ï¼Œæ¯æ®µçº¦ {segment_duration}s")
        
        # ä¸´æ—¶ç›®å½•ç”¨äºä¿å­˜åˆ†æ®µè§†é¢‘
        temp_dir = os.path.join(os.path.dirname(self.output_path) or os.getcwd(), "_segments")
        try:
            if not os.path.exists(temp_dir):
                os.makedirs(temp_dir)
        except Exception:
            # å›é€€åˆ°å½“å‰ç›®å½•
            temp_dir = os.getcwd()
        
        temp_segment_paths = []
        
        for i in range(num_segments):
            start_time = i * segment_duration
            end_time = min((i + 1) * segment_duration, audio_duration)
            segment_audio_duration = end_time - start_time
            
            self.log_updated.emit(f"å¤„ç†ç¬¬ {i+1}/{num_segments} æ®µ: {start_time:.1f}s - {end_time:.1f}s")
            
            # ä¸ºå½“å‰æ®µè½åˆ›å»ºéŸ³é¢‘ç‰‡æ®µ
            segment_audio = audio_clip.subclip(start_time, end_time)
            
            # ä¸ºå½“å‰æ®µè½åˆ†é…å›¾ç‰‡ç‰‡æ®µ
            segment_clips = self.allocate_clips_for_segment(clips, segment_audio_duration, i, num_segments)
            
            # å¤„ç†å½“å‰æ®µè½çš„è§†é¢‘ç‰‡æ®µ
            if self.enable_video_clips:
                segment_clips = self.insert_video_clips(segment_clips, segment_audio_duration, image_files)
            
            # æ‹¼æ¥å½“å‰æ®µè½çš„è§†é¢‘
            if segment_clips:
                if self.resolution:
                    segment_video = concatenate_videoclips(segment_clips, method="chain")
                else:
                    segment_video = concatenate_videoclips(segment_clips)
                
                # åŒæ­¥åˆ°éŸ³é¢‘é•¿åº¦
                if segment_video.duration < segment_audio_duration:
                    # å»¶é•¿è§†é¢‘
                    extend_duration = segment_audio_duration - segment_video.duration
                    last_frame = segment_video.subclip(segment_video.duration - 0.1, segment_video.duration)
                    extended_clip = last_frame.loop(duration=extend_duration)
                    segment_video = concatenate_videoclips([segment_video, extended_clip])
                elif segment_video.duration > segment_audio_duration:
                    # ç¼©çŸ­è§†é¢‘
                    segment_video = segment_video.subclip(0, segment_audio_duration)
                
                # è®¾ç½®éŸ³é¢‘å¹¶å¯¼å‡ºä¸ºä¸´æ—¶æ–‡ä»¶ï¼Œé‡Šæ”¾å†…å­˜
                segment_video = segment_video.set_audio(segment_audio)
                temp_path = os.path.join(temp_dir, f"segment_{i+1:03d}.mp4")
                self.log_updated.emit(f"å¯¼å‡ºç¬¬ {i+1} æ®µåˆ°ä¸´æ—¶æ–‡ä»¶: {os.path.basename(temp_path)}")
                
                # ä½¿ç”¨å®‰å…¨çš„å¯¼å‡ºå‡½æ•°
                safe_write_videofile(
                    segment_video,
                    temp_path,
                    fps=self.fps,
                    preset=self.preset,
                    crf=23,
                    threads=self.threads,
                    audio_codec='aac'
                )
                # å…³é—­é‡Šæ”¾å†…å­˜
                try:
                    segment_video.close()
                except Exception:
                    pass
                try:
                    segment_audio.close()
                except Exception:
                    pass
                temp_segment_paths.append(temp_path)
                self.temp_segment_files.append(temp_path)
                
                self.log_updated.emit(f"âœ“ ç¬¬ {i+1} æ®µå¤„ç†å®Œæˆï¼Œæ—¶é•¿: {segment_audio_duration:.1f}s")
            else:
                self.log_updated.emit(f"âš ï¸ ç¬¬ {i+1} æ®µæ²¡æœ‰å¯ç”¨çš„è§†é¢‘ç‰‡æ®µ")
            
            # å¼ºåˆ¶æ¸…ç†å†…å­˜
            import gc
            gc.collect()
            
            # æ›´æ–°è¿›åº¦
            progress = 85 + (i + 1) * 10 // num_segments
            self.progress_updated.emit(progress)
        
        # æ‹¼æ¥æ‰€æœ‰æ®µè½ï¼ˆåŸºäºç£ç›˜æ–‡ä»¶ï¼Œå†…å­˜å ç”¨æ›´ä½ï¼‰
        if temp_segment_paths:
            self.log_updated.emit("æ‹¼æ¥æ‰€æœ‰æ®µè½(åŸºäºä¸´æ—¶æ–‡ä»¶)...")
            from moviepy.editor import VideoFileClip
            concat_clips = []
            for p in temp_segment_paths:
                try:
                    concat_clips.append(VideoFileClip(p))
                except Exception as e:
                    self.log_updated.emit(f"âœ— åŠ è½½æ®µè½å¤±è´¥ {os.path.basename(p)}: {str(e)}")
            if concat_clips:
                final_video = concatenate_videoclips(concat_clips, method="chain")
                self.log_updated.emit(f"âœ“ åˆ†æ®µå¤„ç†å®Œæˆï¼Œæœ€ç»ˆæ—¶é•¿: {final_video.duration:.1f}s")
                return final_video
            else:
                self.log_updated.emit("âœ— æ— æ³•åŠ è½½ä»»ä½•æ®µè½è§†é¢‘")
                return None
        else:
            self.log_updated.emit("âœ— åˆ†æ®µå¤„ç†å¤±è´¥ï¼Œæ²¡æœ‰ç”Ÿæˆä»»ä½•æ®µè½")
            return None
    
    def allocate_clips_for_segment(self, clips, segment_duration, segment_index, total_segments):
        """ä¸ºæ®µè½åˆ†é…å›¾ç‰‡ç‰‡æ®µ"""
        if not clips:
            return []
        
        # è®¡ç®—å½“å‰æ®µè½åº”è¯¥ä½¿ç”¨çš„å›¾ç‰‡æ•°é‡
        total_duration = sum(clip.duration for clip in clips)
        if total_duration == 0:
            return []
        
        # æŒ‰æ¯”ä¾‹åˆ†é…å›¾ç‰‡ç‰‡æ®µ
        segment_ratio = segment_duration / total_duration
        num_clips = max(1, int(len(clips) * segment_ratio))
        
        # é€‰æ‹©å›¾ç‰‡ç‰‡æ®µ
        start_index = segment_index * num_clips
        end_index = min(start_index + num_clips, len(clips))
        segment_clips = clips[start_index:end_index]
        
        self.log_updated.emit(f"æ®µè½ {segment_index + 1}: åˆ†é…äº† {len(segment_clips)} ä¸ªå›¾ç‰‡ç‰‡æ®µ")
        return segment_clips
    
    def move_processed_images(self):
        """ç§»åŠ¨å·²å¤„ç†çš„å›¾ç‰‡åˆ°å·²å¤„ç†æ–‡ä»¶å¤¹"""
        try:
            self.log_updated.emit("æ­¥éª¤8: ç§»åŠ¨å·²å¤„ç†å›¾ç‰‡...")
            self.status_updated.emit("ç§»åŠ¨å·²å¤„ç†å›¾ç‰‡...")
            
            # åªç§»åŠ¨å®é™…å¤„ç†çš„å›¾ç‰‡
            processed_images = self.actually_processed_images
            
            if not processed_images:
                self.log_updated.emit("æ²¡æœ‰æ‰¾åˆ°éœ€è¦ç§»åŠ¨çš„å·²å¤„ç†å›¾ç‰‡æ–‡ä»¶")
                return
            
            # ç¡®ä¿å·²å¤„ç†æ–‡ä»¶å¤¹å­˜åœ¨
            if not os.path.exists(self.processed_folder):
                os.makedirs(self.processed_folder)
                self.log_updated.emit(f"åˆ›å»ºå·²å¤„ç†æ–‡ä»¶å¤¹: {self.processed_folder}")
            
            moved_count = 0
            for image_path in processed_images:
                try:
                    filename = os.path.basename(image_path)
                    destination = os.path.join(self.processed_folder, filename)
                    
                    # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³
                    if os.path.exists(destination):
                        name, ext = os.path.splitext(filename)
                        timestamp = int(time.time())
                        filename = f"{name}_{timestamp}{ext}"
                        destination = os.path.join(self.processed_folder, filename)
                    
                    # ç§»åŠ¨æ–‡ä»¶
                    shutil.move(image_path, destination)
                    moved_count += 1
                    self.log_updated.emit(f"âœ“ å·²ç§»åŠ¨: {filename}")
                    
                except Exception as e:
                    self.log_updated.emit(f"âœ— ç§»åŠ¨å¤±è´¥ {os.path.basename(image_path)}: {str(e)}")
                    continue
            
            self.log_updated.emit(f"âœ“ å·²ç§»åŠ¨ {moved_count} å¼ å·²å¤„ç†çš„å›¾ç‰‡åˆ°å·²å¤„ç†æ–‡ä»¶å¤¹")
            self.log_updated.emit(f"æ€»å…±å¤„ç†äº† {len(self.actually_processed_images)} å¼ å›¾ç‰‡ï¼Œç§»åŠ¨äº† {moved_count} å¼ ")
            
        except Exception as e:
            self.log_updated.emit(f"âœ— ç§»åŠ¨å·²å¤„ç†å›¾ç‰‡å¤±è´¥: {str(e)}")
    
    def move_processed_videos(self):
        """ç§»åŠ¨å·²å¤„ç†çš„è§†é¢‘ç‰‡æ®µåˆ°å·²å¤„ç†è§†é¢‘ç‰‡æ®µæ–‡ä»¶å¤¹"""
        try:
            self.log_updated.emit("æ­¥éª¤9: ç§»åŠ¨å·²å¤„ç†è§†é¢‘ç‰‡æ®µ...")
            self.status_updated.emit("ç§»åŠ¨å·²å¤„ç†è§†é¢‘ç‰‡æ®µ...")
            
            # åªç§»åŠ¨å®é™…å¤„ç†çš„è§†é¢‘ç‰‡æ®µ
            processed_videos = self.actually_processed_videos
            
            if not processed_videos:
                self.log_updated.emit("æ²¡æœ‰æ‰¾åˆ°éœ€è¦ç§»åŠ¨çš„å·²å¤„ç†è§†é¢‘ç‰‡æ®µæ–‡ä»¶")
                return
            
            # ç¡®ä¿å·²å¤„ç†è§†é¢‘ç‰‡æ®µæ–‡ä»¶å¤¹å­˜åœ¨
            if not os.path.exists(self.processed_video_folder):
                os.makedirs(self.processed_video_folder)
                self.log_updated.emit(f"åˆ›å»ºå·²å¤„ç†è§†é¢‘ç‰‡æ®µæ–‡ä»¶å¤¹: {self.processed_video_folder}")
            
            moved_count = 0
            for video_path in processed_videos:
                try:
                    filename = os.path.basename(video_path)
                    destination = os.path.join(self.processed_video_folder, filename)
                    
                    # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³
                    if os.path.exists(destination):
                        name, ext = os.path.splitext(filename)
                        timestamp = int(time.time())
                        filename = f"{name}_{timestamp}{ext}"
                        destination = os.path.join(self.processed_video_folder, filename)
                    
                    # ç§»åŠ¨æ–‡ä»¶
                    shutil.move(video_path, destination)
                    moved_count += 1
                    self.log_updated.emit(f"âœ“ å·²ç§»åŠ¨: {filename}")
                    
                except Exception as e:
                    self.log_updated.emit(f"âœ— ç§»åŠ¨å¤±è´¥ {os.path.basename(video_path)}: {str(e)}")
                    continue
            
            self.log_updated.emit(f"âœ“ å·²ç§»åŠ¨ {moved_count} ä¸ªå·²å¤„ç†çš„è§†é¢‘ç‰‡æ®µåˆ°å·²å¤„ç†è§†é¢‘ç‰‡æ®µæ–‡ä»¶å¤¹")
            self.log_updated.emit(f"æ€»å…±å¤„ç†äº† {len(self.actually_processed_videos)} ä¸ªè§†é¢‘ç‰‡æ®µï¼Œç§»åŠ¨äº† {moved_count} ä¸ª")
            
        except Exception as e:
            self.log_updated.emit(f"âœ— ç§»åŠ¨å·²å¤„ç†è§†é¢‘ç‰‡æ®µå¤±è´¥: {str(e)}")
    
    def get_video_clips(self):
        """è·å–è§†é¢‘ç‰‡æ®µæ–‡ä»¶åˆ—è¡¨"""
        if not self.enable_video_clips or not self.video_clip_folder or not os.path.exists(self.video_clip_folder):
            return []
        
        video_clips = []
        for file in os.listdir(self.video_clip_folder):
            if any(file.lower().endswith(ext) for ext in self.video_extensions):
                video_clips.append(os.path.join(self.video_clip_folder, file))
        
        # éšæœºé€‰æ‹©æŒ‡å®šæ•°é‡çš„è§†é¢‘ç‰‡æ®µ
        if len(video_clips) > self.video_clip_count:
            video_clips = random.sample(video_clips, self.video_clip_count)
        
        return sorted(video_clips)
    
    def insert_video_clips(self, clips, audio_duration, image_files):
        """åœ¨è§†é¢‘ç‰‡æ®µä¸­æ’å…¥è§†é¢‘ç‰‡æ®µ - å†…å­˜ä¼˜åŒ–ç‰ˆæœ¬"""
        if not self.enable_video_clips or not clips:
            return clips
        
        video_clips = self.get_video_clips()
        if not video_clips:
            self.log_updated.emit("æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„è§†é¢‘ç‰‡æ®µ")
            return clips
        
        self.log_updated.emit(f"æ‰¾åˆ° {len(video_clips)} ä¸ªè§†é¢‘ç‰‡æ®µï¼Œå‡†å¤‡æ’å…¥")
        
        # æ˜¾ç¤ºç³»ç»Ÿå†…å­˜ä¿¡æ¯
        memory_info = psutil.virtual_memory()
        self.log_updated.emit(f"ç³»ç»Ÿå†…å­˜ä¿¡æ¯: æ€»è®¡ {memory_info.total // (1024**3)}GB, å¯ç”¨ {memory_info.available // (1024**3)}GB, ä½¿ç”¨ç‡ {memory_info.percent:.1f}%")
        
        try:
            from moviepy.editor import VideoFileClip, concatenate_videoclips
            import gc
            import ctypes
            
            # ç¬¬ä¸€æ­¥ï¼šè·å–éŸ³é¢‘æ—¶é•¿
            self.log_updated.emit(f"éŸ³é¢‘æ—¶é•¿: {audio_duration:.1f}s")
            
            # å¼ºåˆ¶å†…å­˜é‡Šæ”¾å‡½æ•°
            def force_memory_cleanup():
                """å¼ºåˆ¶å†…å­˜æ¸…ç†å’Œå‹ç¼©"""
                try:
                    # å¼ºåˆ¶åƒåœ¾å›æ”¶
                    gc.collect()
                    gc.collect()
                    
                    # å°è¯•å‹ç¼©å†…å­˜ï¼ˆWindowsï¼‰
                    try:
                        ctypes.windll.kernel32.SetProcessWorkingSetSize(-1, -1, -1)
                    except:
                        pass
                    
                    # è·å–å½“å‰å†…å­˜ä½¿ç”¨ç‡
                    memory_percent = psutil.virtual_memory().percent
                    return memory_percent
                except Exception as e:
                    self.log_updated.emit(f"å†…å­˜æ¸…ç†å¤±è´¥: {str(e)}")
                    return psutil.virtual_memory().percent
            
            # ç¬¬äºŒæ­¥ï¼šåˆ†æ‰¹å¤„ç†è§†é¢‘ç‰‡æ®µï¼Œé¿å…å†…å­˜æº¢å‡º
            video_clip_data = []
            total_video_duration = 0
            
            # æ ¹æ®è§†é¢‘ç‰‡æ®µæ•°é‡å’Œå†…å­˜ä½¿ç”¨æƒ…å†µåŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°
            current_memory = force_memory_cleanup()
            self.log_updated.emit(f"åˆå§‹å†…å­˜ä½¿ç”¨ç‡: {current_memory:.1f}%")
            
            if current_memory > 95:
                batch_size = 1  # å†…å­˜ä¸¥é‡ä¸è¶³æ—¶ä¸€æ¬¡åªå¤„ç†1ä¸ª
                self.log_updated.emit("å†…å­˜ä¸¥é‡ä¸è¶³ï¼Œä½¿ç”¨æœ€å°æ‰¹æ¬¡å¤§å°")
            elif current_memory > 90:
                batch_size = 1  # å†…å­˜ä¸è¶³æ—¶ä¸€æ¬¡åªå¤„ç†1ä¸ª
                self.log_updated.emit("å†…å­˜ä¸è¶³ï¼Œä½¿ç”¨æœ€å°æ‰¹æ¬¡å¤§å°")
            elif current_memory > 80:
                batch_size = 2  # å†…å­˜è¾ƒé«˜æ—¶ä¸€æ¬¡å¤„ç†2ä¸ª
            elif len(video_clips) <= 10:
                batch_size = 5
            elif len(video_clips) <= 50:
                batch_size = 3
            else:
                batch_size = 2
            
            for i in range(0, len(video_clips), batch_size):
                # åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°
                current_memory = force_memory_cleanup()
                if current_memory > 95:
                    batch_size = 1
                    self.log_updated.emit("å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå¼ºåˆ¶ä½¿ç”¨æœ€å°æ‰¹æ¬¡å¤§å°")
                elif current_memory > 90:
                    batch_size = 2
                    self.log_updated.emit("å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œä½¿ç”¨å°æ‰¹æ¬¡å¤§å°")
                
                batch_videos = video_clips[i:i+batch_size]
                self.log_updated.emit(f"å¤„ç†è§†é¢‘ç‰‡æ®µæ‰¹æ¬¡ {i//batch_size + 1}/{(len(video_clips)-1)//batch_size + 1} ({len(batch_videos)} ä¸ªï¼Œå†…å­˜ä½¿ç”¨ç‡: {current_memory:.1f}%)")
                
                for video_path in batch_videos:
                    try:
                        # æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
                        memory_percent = force_memory_cleanup()
                        if memory_percent > 98:
                            self.log_updated.emit(f"âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ ({memory_percent:.1f}%)ï¼Œè·³è¿‡å½“å‰è§†é¢‘ç‰‡æ®µ")
                            continue
                        elif memory_percent > 95:
                            self.log_updated.emit(f"âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ ({memory_percent:.1f}%)ï¼Œå»ºè®®å‡å°‘è§†é¢‘ç‰‡æ®µæ•°é‡")
                        
                        video_clip = VideoFileClip(video_path)
                        video_clip = video_clip.without_audio()
                        
                        # æ™ºèƒ½è°ƒæ•´è§†é¢‘ç‰‡æ®µæ—¶é•¿ä»¥é€‚åº”éŸ³é¢‘
                        original_duration = video_clip.duration
                        
                        # æ ¹æ®éŸ³é¢‘æ—¶é•¿å’Œè§†é¢‘ç‰‡æ®µæ•°é‡åŠ¨æ€è°ƒæ•´æœ€å¤§æ—¶é•¿
                        estimated_video_count = len(video_clips)
                        max_allowed_duration = min(10.0, audio_duration / max(estimated_video_count, 1) * 0.8)  # é™ä½æœ€å¤§æ—¶é•¿
                        min_allowed_duration = 1.0
                        
                        if original_duration > max_allowed_duration:
                            start_time = (original_duration - max_allowed_duration) / 2
                            video_clip = video_clip.subclip(start_time, start_time + max_allowed_duration)
                            actual_duration = max_allowed_duration
                            self.log_updated.emit(f"è§†é¢‘ç‰‡æ®µè¿‡é•¿ï¼Œä»ä¸­é—´æˆªå–: {os.path.basename(video_path)} ({original_duration:.1f}s -> {actual_duration:.1f}s)")
                        elif original_duration < min_allowed_duration:
                            loops_needed = int(min_allowed_duration / original_duration) + 1
                            video_clips_loop = [video_clip] * loops_needed
                            video_clip = concatenate_videoclips(video_clips_loop).subclip(0, min_allowed_duration)
                            actual_duration = min_allowed_duration
                            self.log_updated.emit(f"è§†é¢‘ç‰‡æ®µè¿‡çŸ­ï¼Œå¾ªç¯æ’­æ”¾: {os.path.basename(video_path)} ({original_duration:.1f}s -> {actual_duration:.1f}s)")
                        else:
                            actual_duration = original_duration
                            self.log_updated.emit(f"è§†é¢‘ç‰‡æ®µæ—¶é•¿åˆé€‚: {os.path.basename(video_path)} ({actual_duration:.1f}s)")
                        
                        video_clip_data.append({
                            'clip': video_clip,
                            'duration': actual_duration,
                            'path': video_path
                        })
                        total_video_duration += actual_duration
                        
                    except Exception as e:
                        self.log_updated.emit(f"âœ— åŠ è½½è§†é¢‘ç‰‡æ®µå¤±è´¥ {os.path.basename(video_path)}: {str(e)}")
                        continue
                
                # æ¯æ‰¹å¤„ç†å®Œåå¼ºåˆ¶æ¸…ç†å†…å­˜
                current_memory = force_memory_cleanup()
                self.log_updated.emit(f"æ‰¹æ¬¡å¤„ç†å®Œæˆï¼Œå½“å‰å†…å­˜ä½¿ç”¨ç‡: {current_memory:.1f}%")
                
                # å¦‚æœå†…å­˜ä½¿ç”¨ç‡ä»ç„¶å¾ˆé«˜ï¼Œè¿›è¡Œæ·±åº¦æ¸…ç†
                if current_memory > 90:
                    self.log_updated.emit("å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œè¿›è¡Œæ·±åº¦æ¸…ç†...")
                    # æ¸…ç†å·²å¤„ç†çš„è§†é¢‘ç‰‡æ®µ
                    for data in video_clip_data:
                        if 'clip' in data:
                            try:
                                data['clip'].close()
                            except:
                                pass
                    # å†æ¬¡å¼ºåˆ¶æ¸…ç†
                    force_memory_cleanup()
            
            if not video_clip_data:
                self.log_updated.emit("æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•è§†é¢‘ç‰‡æ®µ")
                # å¦‚æœå†…å­˜ä¸è¶³å¯¼è‡´æ— æ³•åŠ è½½è§†é¢‘ç‰‡æ®µï¼Œå»ºè®®ç”¨æˆ·å‡å°‘è§†é¢‘ç‰‡æ®µæ•°é‡
                current_memory = force_memory_cleanup()
                if current_memory > 90:
                    self.log_updated.emit("å»ºè®®ï¼šå†…å­˜ä¸è¶³ï¼Œè¯·å‡å°‘è§†é¢‘ç‰‡æ®µæ•°é‡æˆ–å…³é—­å…¶ä»–ç¨‹åº")
                    self.log_updated.emit("å½“å‰ç³»ç»Ÿå†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®ï¼š")
                    self.log_updated.emit("1. å…³é—­å…¶ä»–å ç”¨å†…å­˜çš„ç¨‹åº")
                    self.log_updated.emit("2. å‡å°‘è§†é¢‘ç‰‡æ®µæ•°é‡")
                    self.log_updated.emit("3. æ£€æŸ¥æ˜¯å¦æœ‰å†…å­˜æ³„æ¼")
                return clips
            
            self.log_updated.emit(f"è§†é¢‘ç‰‡æ®µæ€»æ—¶é•¿: {total_video_duration:.1f}s")
            
            # ç¬¬ä¸‰æ­¥ï¼šæ™ºèƒ½åˆ†é…æ—¶é—´
            # å¦‚æœè§†é¢‘ç‰‡æ®µæ€»æ—¶é•¿è¶…è¿‡éŸ³é¢‘çš„80%ï¼Œåˆ™æŒ‰æ¯”ä¾‹ç¼©çŸ­æ‰€æœ‰è§†é¢‘ç‰‡æ®µ
            if total_video_duration > audio_duration * 0.8:
                scale_factor = (audio_duration * 0.8) / total_video_duration
                self.log_updated.emit(f"è§†é¢‘ç‰‡æ®µæ€»æ—¶é•¿({total_video_duration:.1f}s)è¿‡é•¿ï¼ŒæŒ‰æ¯”ä¾‹ç¼©çŸ­åˆ° {audio_duration * 0.8:.1f}s")
                
                # é‡æ–°è®¡ç®—æ‰€æœ‰è§†é¢‘ç‰‡æ®µçš„æ—¶é•¿
                total_video_duration = 0
                for data in video_clip_data:
                    new_duration = data['duration'] * scale_factor
                    data['duration'] = new_duration
                    data['clip'] = data['clip'].subclip(0, new_duration)
                    total_video_duration += new_duration
                    self.log_updated.emit(f"ç¼©çŸ­è§†é¢‘ç‰‡æ®µ: {os.path.basename(data['path'])} -> {new_duration:.1f}s")
            
            remaining_time = audio_duration - total_video_duration
            self.log_updated.emit(f"å‰©ä½™æ—¶é—´ç»™å›¾ç‰‡: {remaining_time:.1f}s")
            
            if remaining_time <= 0:
                self.log_updated.emit(f"è­¦å‘Š: è§†é¢‘ç‰‡æ®µæ€»æ—¶é•¿({total_video_duration:.1f}s)è¶…è¿‡éŸ³é¢‘æ—¶é•¿({audio_duration:.1f}s)")
                remaining_time = audio_duration * 0.1
                self.log_updated.emit(f"è°ƒæ•´åå‰©ä½™æ—¶é—´: {remaining_time:.1f}s")
            
            # ç¬¬å››æ­¥ï¼šæ ¹æ®å‰©ä½™æ—¶é—´é‡æ–°ç”Ÿæˆå›¾ç‰‡ç‰‡æ®µ
            self.log_updated.emit(f"ä½¿ç”¨å‰©ä½™æ—¶é•¿ {remaining_time:.1f}s é‡æ–°ç”Ÿæˆå›¾ç‰‡ç‰‡æ®µ")
            
            # æ¸…ç©ºç°æœ‰å›¾ç‰‡ç‰‡æ®µ
            clips = []
            
            # æ ¹æ®å‰©ä½™æ—¶é—´å’Œå›¾ç‰‡æ—¶é•¿èŒƒå›´è®¡ç®—èƒ½æ”¾å¤šå°‘å¼ å›¾ç‰‡
            if isinstance(self.image_duration, tuple):
                dmin, dmax = self.image_duration
            else:
                dmin = dmax = float(self.image_duration)
            
            self.log_updated.emit(f"å›¾ç‰‡æ—¶é•¿èŒƒå›´: {dmin}-{dmax}s, å‰©ä½™æ—¶é—´: {remaining_time:.1f}s")
            
            # è®¡ç®—èƒ½æ”¾å¤šå°‘å¼ å›¾ç‰‡
            if dmin <= 0:
                self.log_updated.emit(f"é”™è¯¯: å›¾ç‰‡æœ€å°æ—¶é•¿({dmin})å¿…é¡»å¤§äº0")
                max_images = 0
            else:
                max_images = int(remaining_time / dmin)
                self.log_updated.emit(f"æœ€å¤šå¯æ”¾: {max_images}å¼ å›¾ç‰‡")
            
            if max_images > 0 and len(image_files) > 0:
                # é‡æ–°ç”Ÿæˆå›¾ç‰‡ç‰‡æ®µï¼Œä½¿ç”¨å‰©ä½™æ—¶é—´
                current_time = 0.0
                for i in range(min(max_images, len(image_files))):
                    # è®¡ç®—å½“å‰ç‰‡æ®µæ—¶é•¿
                    remaining_for_this_image = remaining_time - current_time
                    if remaining_for_this_image <= 0:
                        break
                    
                    # åœ¨èŒƒå›´å†…éšæœºï¼Œä½†ä¸è¶…è¿‡å‰©ä½™æ—¶é—´
                    if isinstance(self.image_duration, tuple):
                        rnd = random.random()
                        desired = dmin + (dmax - dmin) * rnd
                    else:
                        desired = float(self.image_duration)
                    
                    self.log_updated.emit(f"è®¡ç®—å›¾ç‰‡ç‰‡æ®µ{i+1}: desired={desired:.1f}s, remaining={remaining_for_this_image:.1f}s")
                    
                    if desired <= 0 or remaining_for_this_image <= 0:
                        self.log_updated.emit(f"è·³è¿‡å›¾ç‰‡ç‰‡æ®µ{i+1}: desired={desired:.1f}s, remaining={remaining_for_this_image:.1f}s")
                        break
                    
                    clip_duration = min(desired, remaining_for_this_image)
                    
                    if clip_duration <= 0:
                        break
                    
                    try:
                        # é€‰æ‹©åŠ¨ç”»æ•ˆæœ
                        effect = self.animation_effect
                        if effect == "éšæœºæ•ˆæœ":
                            effects = ['Slow Zoom In', 'Slow Zoom Out', 'Pan Left to Right', 'Pan Right to Left']
                            effect = random.choice(effects)
                        
                        # åˆ›å»ºå›¾ç‰‡ç‰‡æ®µ
                        clip = create_animated_clip(
                            image_files[i], 
                            clip_duration, 
                            effect, 
                            self.animation_intensity,
                            self.resolution
                        )
                        
                        clips.append(clip)
                        current_time += clip_duration
                        self.log_updated.emit(f"é‡æ–°ç”Ÿæˆå›¾ç‰‡ç‰‡æ®µ{i+1}: {os.path.basename(image_files[i])}, æ—¶é•¿={clip_duration:.1f}s")
                        
                    except Exception as e:
                        self.log_updated.emit(f"é‡æ–°ç”Ÿæˆå›¾ç‰‡ç‰‡æ®µå¤±è´¥ {os.path.basename(image_files[i])}: {str(e)}")
                        break
                
                # éªŒè¯é‡æ–°ç”Ÿæˆåçš„æ€»æ—¶é•¿
                total_image_duration = sum(clip.duration for clip in clips)
                self.log_updated.emit(f"é‡æ–°ç”Ÿæˆåå›¾ç‰‡ç‰‡æ®µæ€»æ—¶é•¿: {total_image_duration:.1f}s")
            else:
                self.log_updated.emit(f"å‰©ä½™æ—¶é—´ä¸è¶³ï¼Œæ— æ³•ç”Ÿæˆå›¾ç‰‡ç‰‡æ®µ")
            
            # ç¬¬å…­æ­¥ï¼šåˆ›å»ºæœ€ç»ˆè§†é¢‘åºåˆ— - éšæœºç©¿æ’å›¾ç‰‡å’Œè§†é¢‘ç‰‡æ®µ
            final_clips = []
            
            # åˆ›å»ºæ‰€æœ‰ç‰‡æ®µçš„åˆ—è¡¨ï¼ˆå›¾ç‰‡ + è§†é¢‘ï¼‰
            all_segments = []
            
            # ç¡®ä¿clipsä¸ä¸ºç©º
            if not clips:
                self.log_updated.emit("è­¦å‘Š: æ²¡æœ‰å›¾ç‰‡ç‰‡æ®µï¼Œæ— æ³•åˆ›å»ºè§†é¢‘")
                return []
            
            # æ·»åŠ å›¾ç‰‡ç‰‡æ®µ
            for i, clip in enumerate(clips):
                all_segments.append({
                    'type': 'image',
                    'clip': clip,
                    'duration': clip.duration,
                    'name': f'å›¾ç‰‡ç‰‡æ®µ{i+1}'
                })
            
            # æ·»åŠ è§†é¢‘ç‰‡æ®µ
            for i, data in enumerate(video_clip_data):
                try:
                    video_clip = data['clip']
                    if self.resolution:
                        video_clip = self._adjust_video_clip_resolution(video_clip)
                    
                    # è·Ÿè¸ªå®é™…å¤„ç†çš„è§†é¢‘ç‰‡æ®µ
                    self.actually_processed_videos.append(data['path'])
                    
                    all_segments.append({
                        'type': 'video',
                        'clip': video_clip,
                        'duration': data['duration'],
                        'name': f'è§†é¢‘ç‰‡æ®µ{i+1}: {os.path.basename(data["path"])}'
                    })
                    
                except Exception as e:
                    self.log_updated.emit(f"âœ— å¤„ç†è§†é¢‘ç‰‡æ®µå¤±è´¥ {os.path.basename(data['path'])}: {str(e)}")
            
            # éšæœºæ‰“ä¹±ç‰‡æ®µé¡ºåº
            random.shuffle(all_segments)
            self.log_updated.emit(f"éšæœºæ‰“ä¹±ç‰‡æ®µé¡ºåºï¼Œå…± {len(all_segments)} ä¸ªç‰‡æ®µ")
            
            # æŒ‰é¡ºåºæ·»åŠ æ‰€æœ‰ç‰‡æ®µ
            for i, segment in enumerate(all_segments):
                final_clips.append(segment['clip'])
                self.log_updated.emit(f"âœ“ æ·»åŠ {segment['name']}: æ—¶é•¿={segment['duration']:.1f}s")
            
            # è®¡ç®—æœ€ç»ˆæ€»æ—¶é•¿
            total_duration = sum(clip.duration for clip in final_clips)
            self.log_updated.emit(f"æœ€ç»ˆè§†é¢‘æ€»æ—¶é•¿: {total_duration:.1f}s (ç›®æ ‡éŸ³é¢‘æ—¶é•¿: {audio_duration:.1f}s)")
            
            if abs(total_duration - audio_duration) > 0.1:
                self.log_updated.emit(f"è­¦å‘Š: è§†é¢‘æ—¶é•¿({total_duration:.1f}s)ä¸éŸ³é¢‘æ—¶é•¿({audio_duration:.1f}s)ä¸åŒ¹é…ï¼")
            
            return final_clips
            
        except Exception as e:
            self.log_updated.emit(f"âœ— è§†é¢‘ç‰‡æ®µæ’å…¥å¤±è´¥: {str(e)}")
            # å¦‚æœè§†é¢‘ç‰‡æ®µæ’å…¥å¤±è´¥ï¼Œè¿”å›åŸå§‹clips
            return clips
    
    def _adjust_video_clip_resolution(self, video_clip):
        """è°ƒæ•´è§†é¢‘ç‰‡æ®µåˆ†è¾¨ç‡"""
        if not self.resolution:
            return video_clip
            
        target_width, target_height = self.resolution
        original_width, original_height = video_clip.size
        
        # å¦‚æœå°ºå¯¸å·²ç»åŒ¹é…ï¼Œæ— éœ€è°ƒæ•´
        if original_width == target_width and original_height == target_height:
            self.log_updated.emit(f"è§†é¢‘ç‰‡æ®µå°ºå¯¸å·²åŒ¹é…: {original_width}x{original_height}")
            return video_clip
        
        # æ ¹æ®ç¼©æ”¾æ¨¡å¼å¤„ç†
        if self.video_clip_scale_mode == "stretch":
            # æ‹‰ä¼¸æ¨¡å¼ï¼šå¼ºåˆ¶è°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸ï¼ˆå¯èƒ½å˜å½¢ï¼‰
            video_clip = video_clip.resize((target_width, target_height))
            self.log_updated.emit(f"æ‹‰ä¼¸è§†é¢‘ç‰‡æ®µ: {original_width}x{original_height} -> {target_width}x{target_height}")
            
        elif self.video_clip_scale_mode == "fit":
            # é€‚åº”æ¨¡å¼ï¼šä¿æŒæ¯”ä¾‹ï¼Œæ·»åŠ é»‘è¾¹
            width_ratio = target_width / original_width
            height_ratio = target_height / original_height
            scale_ratio = min(width_ratio, height_ratio)  # é€‰æ‹©è¾ƒå°çš„æ¯”ä¾‹
            
            new_width = int(original_width * scale_ratio)
            new_height = int(original_height * scale_ratio)
            
            # ç¼©æ”¾åˆ°åˆé€‚å°ºå¯¸
            video_clip = video_clip.resize((new_width, new_height))
            
            # å¦‚æœå°ºå¯¸ä¸åŒ¹é…ï¼Œæ·»åŠ é»‘è¾¹
            if new_width != target_width or new_height != target_height:
                # åˆ›å»ºé»‘è‰²èƒŒæ™¯
                from moviepy.editor import ColorClip, CompositeVideoClip
                background = ColorClip(size=(target_width, target_height), color=(0, 0, 0), duration=video_clip.duration)
                
                # è®¡ç®—å±…ä¸­ä½ç½®
                x_offset = (target_width - new_width) // 2
                y_offset = (target_height - new_height) // 2
                
                # å°†è§†é¢‘ç‰‡æ®µåˆæˆåˆ°èƒŒæ™¯ä¸Š
                video_clip = CompositeVideoClip([background, video_clip.set_position((x_offset, y_offset))])
            
            self.log_updated.emit(f"é€‚åº”æ¨¡å¼è°ƒæ•´: {original_width}x{original_height} -> {target_width}x{target_height} (ä¿æŒæ¯”ä¾‹)")
            
        else:  # crop æ¨¡å¼ï¼ˆé»˜è®¤ï¼‰
            # è£å‰ªæ¨¡å¼ï¼šä¿æŒæ¯”ä¾‹ï¼Œå±…ä¸­è£å‰ª
            width_ratio = target_width / original_width
            height_ratio = target_height / original_height
            scale_ratio = max(width_ratio, height_ratio)  # é€‰æ‹©è¾ƒå¤§çš„æ¯”ä¾‹ç¡®ä¿å¡«æ»¡ç›®æ ‡å°ºå¯¸
            
            new_width = int(original_width * scale_ratio)
            new_height = int(original_height * scale_ratio)
            
            # å…ˆç¼©æ”¾åˆ°åˆé€‚å°ºå¯¸
            video_clip = video_clip.resize((new_width, new_height))
            
            # å±…ä¸­è£å‰ªåˆ°ç›®æ ‡å°ºå¯¸
            x_center = new_width // 2
            y_center = new_height // 2
            x1 = x_center - target_width // 2
            y1 = y_center - target_height // 2
            x2 = x1 + target_width
            y2 = y1 + target_height
            
            video_clip = video_clip.crop(x1=x1, y1=y1, x2=x2, y2=y2)
            
            self.log_updated.emit(f"è£å‰ªæ¨¡å¼è°ƒæ•´: {original_width}x{original_height} -> {target_width}x{target_height} (ä¿æŒæ¯”ä¾‹)")
        
        return video_clip
    
    def stop(self):
        """åœæ­¢çº¿ç¨‹"""
        self._is_running = False
        self.quit()
        self.wait(5000)  # ç­‰å¾…æœ€å¤š5ç§’


class MainWindow(QMainWindow):
    """ä¸»çª—å£"""
    
    def __init__(self):
        super().__init__()
        self.setWindowTitle("Audio-Driven Photo Slideshow Generator")
        self.setGeometry(100, 100, 800, 700)
        
        # åˆå§‹åŒ–é…ç½®ç®¡ç†å™¨
        self.config_manager = ConfigManager()
        
        # åŠ è½½é…ç½®
        self.config = self.config_manager.load_config()
        
        # å­˜å‚¨é€‰æ‹©çš„æ–‡ä»¶è·¯å¾„
        self.selected_image_folder = None
        self.selected_audio_file = None
        self.selected_audio_folder = None
        self.selected_processed_folder = None
        self.selected_output_folder = None
        self.selected_video_clip_folder = None
        self.selected_processed_video_folder = None
        
        # å¤„ç†æ¨¡å¼
        self.processing_mode = "single"  # "single" æˆ– "batch"
        
        # è§†é¢‘ç‰‡æ®µè®¾ç½®
        self.enable_video_clips = False
        self.video_clip_count = 3
        self.video_clip_scale_mode = "crop"  # "crop", "fit", "stretch"
        self.enable_segmented_processing = False  # é»˜è®¤ç¦ç”¨åˆ†æ®µå¤„ç†
        
        # å·¥ä½œçº¿ç¨‹
        self.worker_thread = None
        
        self.setup_ui()
        self.load_config_to_ui()
    
    def closeEvent(self, event):
        """çª—å£å…³é—­äº‹ä»¶"""
        # åœæ­¢å·¥ä½œçº¿ç¨‹
        if self.worker_thread and self.worker_thread.isRunning():
            self.worker_thread.stop()
        
        # æ¥å—å…³é—­äº‹ä»¶
        event.accept()
    
    def load_config_to_ui(self):
        # ä¸´æ—¶ç¦ç”¨è‡ªåŠ¨ä¿å­˜ï¼Œé¿å…åŠ è½½æ—¶è§¦å‘ä¿å­˜
        self._loading_config = True
        
        # åŠ è½½æ–‡ä»¶è·¯å¾„
        if self.config.get("image_folder"):
            self.selected_image_folder = self.config["image_folder"]
            self.image_folder_label.setText(f"å·²é€‰æ‹©: {os.path.basename(self.selected_image_folder)}")
        
        if self.config.get("audio_file"):
            self.selected_audio_file = self.config["audio_file"]
            self.audio_file_label.setText(f"å·²é€‰æ‹©: {os.path.basename(self.selected_audio_file)}")
        
        if self.config.get("audio_folder"):
            self.selected_audio_folder = self.config["audio_folder"]
            self.audio_folder_label.setText(f"å·²é€‰æ‹©: {os.path.basename(self.selected_audio_folder)}")
        
        # åŠ è½½å¤„ç†æ¨¡å¼
        self.processing_mode = self.config.get("processing_mode", "single")
        
        # æ›´æ–°å¤„ç†æ¨¡å¼æŒ‰é’®çŠ¶æ€
        if hasattr(self, 'single_mode_btn') and hasattr(self, 'batch_mode_btn'):
            if self.processing_mode == "single":
                self.single_mode_btn.setChecked(True)
                self.batch_mode_btn.setChecked(False)
            else:
                self.single_mode_btn.setChecked(False)
                self.batch_mode_btn.setChecked(True)
        
        if self.config.get("processed_folder"):
            self.selected_processed_folder = self.config["processed_folder"]
            self.processed_folder_label.setText(f"å·²é€‰æ‹©: {os.path.basename(self.selected_processed_folder)}")
        
        if self.config.get("output_folder"):
            self.selected_output_folder = self.config["output_folder"]
            self.output_folder_label.setText(f"å·²é€‰æ‹©: {os.path.basename(self.selected_output_folder)}")
        
        if self.config.get("video_clip_folder"):
            self.selected_video_clip_folder = self.config["video_clip_folder"]
            self.video_clip_folder_label.setText(f"å·²é€‰æ‹©: {os.path.basename(self.selected_video_clip_folder)}")
        
        if self.config.get("processed_video_folder"):
            self.selected_processed_video_folder = self.config["processed_video_folder"]
            self.processed_video_folder_label.setText(f"å·²é€‰æ‹©: {os.path.basename(self.selected_processed_video_folder)}")
        
        # åŠ è½½è§†é¢‘ç‰‡æ®µè®¾ç½®
        self.enable_video_clips = self.config.get("enable_video_clips", False)
        self.video_clip_count = self.config.get("video_clip_count", 3)
        self.video_clip_scale_mode = self.config.get("video_clip_scale_mode", "crop")
        self.enable_segmented_processing = self.config.get("enable_segmented_processing", False)  # é»˜è®¤ç¦ç”¨
        
        # æ›´æ–°è§†é¢‘ç‰‡æ®µUIçŠ¶æ€
        if hasattr(self, 'enable_video_clips_checkbox'):
            self.enable_video_clips_checkbox.setChecked(self.enable_video_clips)
            self.video_clip_count_spin.setEnabled(self.enable_video_clips)
            if hasattr(self, 'enable_segmented_processing_checkbox'):
                self.enable_segmented_processing_checkbox.setChecked(self.enable_segmented_processing)
            self.video_clip_count_spin.setValue(self.video_clip_count)
            
            # æ›´æ–°ç¼©æ”¾æ¨¡å¼ä¸‹æ‹‰æ¡†
            if hasattr(self, 'video_clip_scale_combo'):
                if self.video_clip_scale_mode == "crop":
                    self.video_clip_scale_combo.setCurrentText("è£å‰ªæ¨¡å¼ (ä¿æŒæ¯”ä¾‹)")
                elif self.video_clip_scale_mode == "fit":
                    self.video_clip_scale_combo.setCurrentText("é€‚åº”æ¨¡å¼ (æ·»åŠ é»‘è¾¹)")
                elif self.video_clip_scale_mode == "stretch":
                    self.video_clip_scale_combo.setCurrentText("æ‹‰ä¼¸æ¨¡å¼ (å¯èƒ½å˜å½¢)")
            
            # æ›´æ–°æŒ‰é’®æ ·å¼
            if self.enable_video_clips:
                self.enable_video_clips_checkbox.setStyleSheet("""
                    QPushButton {
                        background-color: #28a745;
                        color: white;
                        border: none;
                        padding: 8px 16px;
                        border-radius: 4px;
                        font-weight: bold;
                    }
                    QPushButton:hover {
                        background-color: #218838;
                    }
                """)
            else:
                self.enable_video_clips_checkbox.setStyleSheet("""
                    QPushButton {
                        background-color: #6c757d;
                        color: white;
                        border: none;
                        padding: 8px 16px;
                        border-radius: 4px;
                        font-weight: bold;
                    }
                    QPushButton:hover {
                        background-color: #5a6268;
                    }
                """)
        
        # åŠ è½½å‚æ•°è®¾ç½®
        self.duration_min_spin.setValue(self.config.get("image_duration_min", 4.0))
        self.duration_max_spin.setValue(self.config.get("image_duration_max", 6.0))
        
        effect = self.config.get("animation_effect", "Slow Zoom In")
        if effect in get_supported_effects():
            self.effect_combo.setCurrentText(effect)
        
        self.intensity_spinbox.setValue(self.config.get("animation_intensity", 1.0))
        
        # åŠ è½½åˆ†è¾¨ç‡è®¾ç½®
        resolution = self.config.get("resolution", "1920x1080 (16:9)")
        if resolution == "Custom...":
            self.resolution_combo.setCurrentText("Custom...")
            self.custom_width_spin.setValue(self.config.get("custom_width", 1920))
            self.custom_height_spin.setValue(self.config.get("custom_height", 1080))
        else:
            self.resolution_combo.setCurrentText(resolution)
        
        # åŠ è½½å¯¼å‡ºè®¾ç½®
        self.fps_spin.setValue(self.config.get("fps", 24))
        self.preset_combo.setCurrentText(self.config.get("preset", "ultrafast"))
        self.crf_spin.setValue(self.config.get("crf", 23))
        self.threads_spin.setValue(self.config.get("threads", 0))
        
        # é‡æ–°å¯ç”¨è‡ªåŠ¨ä¿å­˜
        self._loading_config = False
    
    def save_config_from_ui(self):
        """å°†å½“å‰UIè®¾ç½®ä¿å­˜åˆ°é…ç½®"""
        config = {
            "image_folder": self.selected_image_folder or "",
            "audio_file": self.selected_audio_file or "",
            "audio_folder": self.selected_audio_folder or "",
            "processed_folder": self.selected_processed_folder or "",
            "output_folder": self.selected_output_folder or "",
            "video_clip_folder": self.selected_video_clip_folder or "",
            "processed_video_folder": self.selected_processed_video_folder or "",
            "processing_mode": self.processing_mode,
            "enable_video_clips": self.enable_video_clips,
            "video_clip_count": self.video_clip_count,
            "video_clip_scale_mode": self.video_clip_scale_mode,
            "enable_segmented_processing": self.enable_segmented_processing,
            "image_duration_min": self.duration_min_spin.value(),
            "image_duration_max": self.duration_max_spin.value(),
            "animation_effect": self.effect_combo.currentText(),
            "animation_intensity": self.intensity_spinbox.value(),
            "resolution": self.resolution_combo.currentText(),
            "custom_width": self.custom_width_spin.value(),
            "custom_height": self.custom_height_spin.value(),
            "fps": self.fps_spin.value(),
            "preset": self.preset_combo.currentText(),
            "crf": self.crf_spin.value(),
            "threads": self.threads_spin.value()
        }
        self.config_manager.save_config(config)
        self.config = config
    
    def setup_ui(self):
        """è®¾ç½®ç”¨æˆ·ç•Œé¢"""
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # ä¸»å¸ƒå±€
        main_layout = QVBoxLayout(central_widget)
        main_layout.setSpacing(10)
        main_layout.setContentsMargins(20, 20, 20, 20)
        
        # æ ‡é¢˜
        title_label = QLabel("éŸ³é¢‘é©±åŠ¨çš„å›¾ç‰‡å¹»ç¯ç‰‡ç”Ÿæˆå™¨")
        title_label.setAlignment(Qt.AlignCenter)
        title_label.setFont(QFont("Arial", 16, QFont.Bold))
        main_layout.addWidget(title_label)
        
        # åˆ›å»ºåˆ†å‰²å™¨
        splitter = QSplitter(Qt.Vertical)
        
        # ä¸ŠåŠéƒ¨åˆ†ï¼šæ§åˆ¶é¢æ¿
        control_widget = QWidget()
        control_layout = QVBoxLayout(control_widget)
        control_layout.setSpacing(15)
        control_layout.setContentsMargins(0, 0, 0, 0)
        
        # è¾“å…¥é€‰æ‹©åŒº
        input_group = self.create_input_selection_group()
        control_layout.addWidget(input_group)
        
        # è¾“å‡ºé€‰æ‹©åŒº
        output_group = self.create_output_selection_group()
        control_layout.addWidget(output_group)
        
        # å‚æ•°é…ç½®åŒº
        config_group = self.create_configuration_group()
        control_layout.addWidget(config_group)
        
        # æ‰§è¡Œä¸åé¦ˆåŒº
        action_group = self.create_action_feedback_group()
        control_layout.addWidget(action_group)
        
        # ä¸‹åŠéƒ¨åˆ†ï¼šæ—¥å¿—é¢æ¿
        log_group = self.create_log_panel()
        
        # æ·»åŠ åˆ°åˆ†å‰²å™¨
        splitter.addWidget(control_widget)
        splitter.addWidget(log_group)
        splitter.setSizes([300, 300])  # è®¾ç½®åˆå§‹å¤§å°æ¯”ä¾‹
        
        main_layout.addWidget(splitter)
    
    def create_input_selection_group(self) -> QGroupBox:
        """åˆ›å»ºè¾“å…¥é€‰æ‹©åŒº"""
        group = QGroupBox("è¾“å…¥é€‰æ‹©")
        layout = QVBoxLayout(group)
        layout.setSpacing(15)
        
        # å›¾ç‰‡æ–‡ä»¶å¤¹é€‰æ‹©
        folder_layout = QHBoxLayout()
        self.folder_btn = QPushButton("é€‰æ‹©å›¾ç‰‡æ–‡ä»¶å¤¹")
        self.folder_btn.clicked.connect(self.select_image_folder)
        self.image_folder_label = QLabel("æœªé€‰æ‹©æ–‡ä»¶å¤¹")
        self.image_folder_label.setWordWrap(True)
        self.image_folder_label.setStyleSheet("color: #666; font-style: italic;")
        
        folder_layout.addWidget(self.folder_btn)
        folder_layout.addWidget(self.image_folder_label, 1)
        layout.addLayout(folder_layout)
        
        # éŸ³é¢‘æ–‡ä»¶é€‰æ‹©
        audio_layout = QHBoxLayout()
        self.audio_btn = QPushButton("é€‰æ‹©éŸ³é¢‘æ–‡ä»¶")
        self.audio_btn.clicked.connect(self.select_audio_file)
        self.audio_file_label = QLabel("æœªé€‰æ‹©éŸ³é¢‘æ–‡ä»¶")
        self.audio_file_label.setWordWrap(True)
        self.audio_file_label.setStyleSheet("color: #666; font-style: italic;")
        
        audio_layout.addWidget(self.audio_btn)
        audio_layout.addWidget(self.audio_file_label, 1)
        layout.addLayout(audio_layout)
        
        # éŸ³é¢‘æ–‡ä»¶å¤¹é€‰æ‹©
        audio_folder_layout = QHBoxLayout()
        self.audio_folder_btn = QPushButton("é€‰æ‹©éŸ³é¢‘æ–‡ä»¶å¤¹")
        self.audio_folder_btn.clicked.connect(self.select_audio_folder)
        self.audio_folder_label = QLabel("æœªé€‰æ‹©éŸ³é¢‘æ–‡ä»¶å¤¹")
        self.audio_folder_label.setWordWrap(True)
        self.audio_folder_label.setStyleSheet("color: #666; font-style: italic;")
        
        audio_folder_layout.addWidget(self.audio_folder_btn)
        audio_folder_layout.addWidget(self.audio_folder_label, 1)
        layout.addLayout(audio_folder_layout)
        
        # å¤„ç†æ¨¡å¼é€‰æ‹©
        mode_layout = QHBoxLayout()
        mode_label = QLabel("å¤„ç†æ¨¡å¼:")
        self.single_mode_btn = QPushButton("å•ä¸ªå¤„ç†")
        self.batch_mode_btn = QPushButton("æ‰¹é‡å¤„ç†")
        
        # è®¾ç½®æŒ‰é’®æ ·å¼
        self.single_mode_btn.setCheckable(True)
        self.batch_mode_btn.setCheckable(True)
        self.single_mode_btn.setChecked(True)  # é»˜è®¤é€‰æ‹©å•ä¸ªå¤„ç†
        
        # è¿æ¥ä¿¡å·
        self.single_mode_btn.clicked.connect(lambda: self.set_processing_mode("single"))
        self.batch_mode_btn.clicked.connect(lambda: self.set_processing_mode("batch"))
        
        mode_layout.addWidget(mode_label)
        mode_layout.addWidget(self.single_mode_btn)
        mode_layout.addWidget(self.batch_mode_btn)
        mode_layout.addStretch()
        layout.addLayout(mode_layout)
        
        # è§†é¢‘ç‰‡æ®µè®¾ç½®
        video_clip_layout = QHBoxLayout()
        self.video_clip_btn = QPushButton("é€‰æ‹©è§†é¢‘ç‰‡æ®µæ–‡ä»¶å¤¹")
        self.video_clip_btn.clicked.connect(self.select_video_clip_folder)
        self.video_clip_folder_label = QLabel("æœªé€‰æ‹©è§†é¢‘ç‰‡æ®µæ–‡ä»¶å¤¹")
        self.video_clip_folder_label.setWordWrap(True)
        self.video_clip_folder_label.setStyleSheet("color: #666; font-style: italic;")
        
        video_clip_layout.addWidget(self.video_clip_btn)
        video_clip_layout.addWidget(self.video_clip_folder_label, 1)
        layout.addLayout(video_clip_layout)
        
        # è§†é¢‘ç‰‡æ®µæ§åˆ¶è®¾ç½®
        video_clip_control_layout = QHBoxLayout()
        
        # æ˜¯å¦æ’å…¥è§†é¢‘ç‰‡æ®µå¼€å…³
        self.enable_video_clips_checkbox = QPushButton("æ’å…¥è§†é¢‘ç‰‡æ®µ")
        self.enable_video_clips_checkbox.setCheckable(True)
        self.enable_video_clips_checkbox.setChecked(False)
        self.enable_video_clips_checkbox.clicked.connect(self.toggle_video_clips)
        
        # è§†é¢‘ç‰‡æ®µæ•°é‡è®¾ç½®
        clip_count_label = QLabel("æ’å…¥æ•°é‡:")
        self.video_clip_count_spin = QDoubleSpinBox()
        self.video_clip_count_spin.setRange(1, 999)  # æ”¹ä¸ºæœ€å¤§999ä¸ª
        self.video_clip_count_spin.setDecimals(0)
        self.video_clip_count_spin.setValue(3)
        self.video_clip_count_spin.setSuffix(" ä¸ª")
        self.video_clip_count_spin.setEnabled(False)
        self.video_clip_count_spin.valueChanged.connect(self.auto_save_config)
        
        # å†…å­˜æç¤ºæ ‡ç­¾
        memory_hint_label = QLabel("æ³¨æ„ï¼šå¤§é‡è§†é¢‘ç‰‡æ®µå¯èƒ½æ¶ˆè€—è¾ƒå¤šå†…å­˜")
        memory_hint_label.setStyleSheet("color: #ff6b6b; font-size: 10px; font-style: italic;")
        memory_hint_label.setWordWrap(True)
        
        # åˆ†æ®µå¤„ç†é€‰é¡¹
        self.enable_segmented_processing_checkbox = QCheckBox("å¯ç”¨åˆ†æ®µå¤„ç†ï¼ˆèŠ‚çœå†…å­˜ï¼‰")
        self.enable_segmented_processing_checkbox.setChecked(self.enable_segmented_processing)
        self.enable_segmented_processing_checkbox.setToolTip("å°†é•¿éŸ³é¢‘åˆ†æˆå¤šä¸ªæ®µè½å¤„ç†ï¼Œå¯ä»¥å¤§å¤§èŠ‚çœå†…å­˜ä½¿ç”¨")
        self.enable_segmented_processing_checkbox.stateChanged.connect(self.on_segmented_processing_toggled)
        
        video_clip_control_layout.addWidget(self.enable_video_clips_checkbox)
        video_clip_control_layout.addWidget(clip_count_label)
        video_clip_control_layout.addWidget(self.video_clip_count_spin)
        video_clip_control_layout.addWidget(memory_hint_label)
        video_clip_control_layout.addWidget(self.enable_segmented_processing_checkbox)
        video_clip_control_layout.addStretch()
        layout.addLayout(video_clip_control_layout)
        
        # è§†é¢‘ç‰‡æ®µç¼©æ”¾æ¨¡å¼è®¾ç½®
        scale_mode_layout = QHBoxLayout()
        scale_mode_label = QLabel("ç¼©æ”¾æ¨¡å¼:")
        self.video_clip_scale_combo = QComboBox()
        self.video_clip_scale_combo.addItems(["è£å‰ªæ¨¡å¼ (ä¿æŒæ¯”ä¾‹)", "é€‚åº”æ¨¡å¼ (æ·»åŠ é»‘è¾¹)", "æ‹‰ä¼¸æ¨¡å¼ (å¯èƒ½å˜å½¢)"])
        self.video_clip_scale_combo.setCurrentText("è£å‰ªæ¨¡å¼ (ä¿æŒæ¯”ä¾‹)")
        self.video_clip_scale_combo.currentTextChanged.connect(self.on_scale_mode_changed)
        
        scale_mode_layout.addWidget(scale_mode_label)
        scale_mode_layout.addWidget(self.video_clip_scale_combo)
        scale_mode_layout.addStretch()
        layout.addLayout(scale_mode_layout)
        
        return group
    
    def create_output_selection_group(self) -> QGroupBox:
        """åˆ›å»ºè¾“å‡ºé€‰æ‹©åŒº"""
        group = QGroupBox("è¾“å‡ºé€‰æ‹©")
        layout = QVBoxLayout(group)
        layout.setSpacing(15)
        
        # è¾“å‡ºè§†é¢‘æ–‡ä»¶å¤¹é€‰æ‹©
        output_layout = QHBoxLayout()
        self.output_btn = QPushButton("é€‰æ‹©è¾“å‡ºè§†é¢‘æ–‡ä»¶å¤¹")
        self.output_btn.clicked.connect(self.select_output_folder)
        self.output_folder_label = QLabel("æœªé€‰æ‹©è¾“å‡ºæ–‡ä»¶å¤¹")
        self.output_folder_label.setWordWrap(True)
        self.output_folder_label.setStyleSheet("color: #666; font-style: italic;")
        
        output_layout.addWidget(self.output_btn)
        output_layout.addWidget(self.output_folder_label, 1)
        layout.addLayout(output_layout)
        
        # å·²å¤„ç†å›¾ç‰‡æ–‡ä»¶å¤¹é€‰æ‹©
        processed_layout = QHBoxLayout()
        self.processed_btn = QPushButton("é€‰æ‹©å·²å¤„ç†å›¾ç‰‡æ–‡ä»¶å¤¹")
        self.processed_btn.clicked.connect(self.select_processed_folder)
        self.processed_folder_label = QLabel("æœªé€‰æ‹©å·²å¤„ç†æ–‡ä»¶å¤¹")
        self.processed_folder_label.setWordWrap(True)
        self.processed_folder_label.setStyleSheet("color: #666; font-style: italic;")
        
        processed_layout.addWidget(self.processed_btn)
        processed_layout.addWidget(self.processed_folder_label, 1)
        layout.addLayout(processed_layout)
        
        # å·²å¤„ç†è§†é¢‘ç‰‡æ®µæ–‡ä»¶å¤¹é€‰æ‹©
        processed_video_layout = QHBoxLayout()
        self.processed_video_btn = QPushButton("é€‰æ‹©å·²å¤„ç†è§†é¢‘ç‰‡æ®µæ–‡ä»¶å¤¹")
        self.processed_video_btn.clicked.connect(self.select_processed_video_folder)
        self.processed_video_folder_label = QLabel("æœªé€‰æ‹©å·²å¤„ç†è§†é¢‘ç‰‡æ®µæ–‡ä»¶å¤¹")
        self.processed_video_folder_label.setWordWrap(True)
        self.processed_video_folder_label.setStyleSheet("color: #666; font-style: italic;")
        
        processed_video_layout.addWidget(self.processed_video_btn)
        processed_video_layout.addWidget(self.processed_video_folder_label, 1)
        layout.addLayout(processed_video_layout)
        
        return group
    
    def create_configuration_group(self) -> QGroupBox:
        """åˆ›å»ºå‚æ•°é…ç½®åŒº"""
        group = QGroupBox("å‚æ•°é…ç½®")
        layout = QVBoxLayout(group)
        layout.setSpacing(15)
        
        # å›¾ç‰‡æ—¶é•¿è®¾ç½®ï¼ˆèŒƒå›´ï¼‰
        duration_layout = QHBoxLayout()
        duration_label = QLabel("æ¯å¼ å›¾ç‰‡æ’­æ”¾æ—¶é•¿èŒƒå›´ (ç§’):")
        self.duration_min_spin = QDoubleSpinBox()
        self.duration_min_spin.setRange(0.1, 60.0)
        self.duration_min_spin.setValue(4.0)
        self.duration_min_spin.setDecimals(1)
        self.duration_min_spin.setSuffix(" ç§’")
        dash_label = QLabel(" - ")
        self.duration_max_spin = QDoubleSpinBox()
        self.duration_max_spin.setRange(0.1, 60.0)
        self.duration_max_spin.setValue(6.0)
        self.duration_max_spin.setDecimals(1)
        self.duration_max_spin.setSuffix(" ç§’")
        
        duration_layout.addWidget(duration_label)
        duration_layout.addWidget(self.duration_min_spin)
        duration_layout.addWidget(dash_label)
        duration_layout.addWidget(self.duration_max_spin)
        duration_layout.addStretch()
        layout.addLayout(duration_layout)
        
        # åŠ¨ç”»æ•ˆæœè®¾ç½®
        effect_layout = QHBoxLayout()
        effect_label = QLabel("åŠ¨ç”»æ•ˆæœ:")
        self.effect_combo = QComboBox()
        
        # æ·»åŠ åŠ¨ç”»æ•ˆæœé€‰é¡¹
        effects = ["éšæœºæ•ˆæœ", "Slow Zoom In", "Slow Zoom Out", 
                  "Pan Left to Right", "Pan Right to Left",
                  "Pan Diagonal Up Right", "Pan Diagonal Up Left",
                  "Pan Diagonal Down Right", "Pan Diagonal Down Left"]
        self.effect_combo.addItems(effects)
        self.effect_combo.setCurrentText("éšæœºæ•ˆæœ")
        
        effect_layout.addWidget(effect_label)
        effect_layout.addWidget(self.effect_combo)
        effect_layout.addStretch()
        layout.addLayout(effect_layout)
        
        # åŠ¨ç”»å¼ºåº¦è®¾ç½®
        intensity_layout = QHBoxLayout()
        intensity_label = QLabel("åŠ¨ç”»å¼ºåº¦:")
        self.intensity_spinbox = QDoubleSpinBox()
        self.intensity_spinbox.setRange(0.1, 3.0)
        self.intensity_spinbox.setValue(1.0)
        self.intensity_spinbox.setDecimals(1)
        self.intensity_spinbox.setSingleStep(0.1)
        self.intensity_spinbox.setSuffix("x")
        
        # æ·»åŠ å¼ºåº¦è¯´æ˜æ ‡ç­¾
        intensity_info = QLabel("(0.1x=è½»å¾®, 1.0x=æ ‡å‡†, 3.0x=å¼ºçƒˆ)")
        intensity_info.setStyleSheet("color: #666; font-size: 11px;")
        
        intensity_layout.addWidget(intensity_label)
        intensity_layout.addWidget(self.intensity_spinbox)
        intensity_layout.addWidget(intensity_info)
        intensity_layout.addStretch()
        layout.addLayout(intensity_layout)

        # åˆ†è¾¨ç‡è®¾ç½®
        resolution_layout = QHBoxLayout()
        resolution_label = QLabel("åˆ†è¾¨ç‡:")
        self.resolution_combo = QComboBox()
        # é¢„ç½®å¸¸ç”¨åˆ†è¾¨ç‡ï¼ˆå®½xé«˜ï¼‰
        self.resolution_combo.addItems([
            "1920x1080 (16:9)",
            "1280x720 (16:9)",
            "2560x1440 (16:9)",
            "3840x2160 (16:9)",
            "1080x1080 (1:1)",
            "1080x1920 (9:16)",
            "Custom..."
        ])
        self.resolution_combo.setCurrentIndex(0)  # é»˜è®¤1920x1080

        # è‡ªå®šä¹‰åˆ†è¾¨ç‡ï¼ˆå¯é€‰ï¼‰
        self.custom_width_spin = QDoubleSpinBox()
        self.custom_width_spin.setRange(320, 7680)
        self.custom_width_spin.setDecimals(0)
        self.custom_width_spin.setValue(1920)
        self.custom_width_spin.setSuffix(" w")
        self.custom_width_spin.setEnabled(False)

        self.custom_height_spin = QDoubleSpinBox()
        self.custom_height_spin.setRange(240, 4320)
        self.custom_height_spin.setDecimals(0)
        self.custom_height_spin.setValue(1080)
        self.custom_height_spin.setSuffix(" h")
        self.custom_height_spin.setEnabled(False)

        def on_resolution_changed(index: int):
            is_custom = (self.resolution_combo.currentText().startswith("Custom"))
            self.custom_width_spin.setEnabled(is_custom)
            self.custom_height_spin.setEnabled(is_custom)

        self.resolution_combo.currentIndexChanged.connect(on_resolution_changed)

        resolution_layout.addWidget(resolution_label)
        resolution_layout.addWidget(self.resolution_combo)
        resolution_layout.addWidget(self.custom_width_spin)
        resolution_layout.addWidget(self.custom_height_spin)
        resolution_layout.addStretch()
        layout.addLayout(resolution_layout)
        
        # è¿æ¥æ‰€æœ‰å‚æ•°æ§ä»¶çš„ä¿¡å·åˆ°è‡ªåŠ¨ä¿å­˜
        self.connect_config_signals()
        
        return group
    
    def connect_config_signals(self):
        """è¿æ¥æ‰€æœ‰å‚æ•°æ§ä»¶çš„ä¿¡å·åˆ°è‡ªåŠ¨ä¿å­˜"""
        # å›¾ç‰‡æ—¶é•¿è®¾ç½®
        self.duration_min_spin.valueChanged.connect(self.auto_save_config)
        self.duration_max_spin.valueChanged.connect(self.auto_save_config)
        
        # åŠ¨ç”»æ•ˆæœè®¾ç½®
        self.effect_combo.currentTextChanged.connect(self.auto_save_config)
        
        # åŠ¨ç”»å¼ºåº¦è®¾ç½®
        self.intensity_spinbox.valueChanged.connect(self.auto_save_config)
        
        # åˆ†è¾¨ç‡è®¾ç½®
        self.resolution_combo.currentTextChanged.connect(self.auto_save_config)
        self.custom_width_spin.valueChanged.connect(self.auto_save_config)
        self.custom_height_spin.valueChanged.connect(self.auto_save_config)

        # åˆ†æ®µå¤„ç†å¼€å…³
        if hasattr(self, 'enable_segmented_processing_checkbox'):
            self.enable_segmented_processing_checkbox.stateChanged.connect(self.on_segmented_processing_toggled)

    def on_segmented_processing_toggled(self):
        """åˆ†æ®µå¤„ç†å¼€å…³åˆ‡æ¢"""
        if hasattr(self, 'enable_segmented_processing_checkbox'):
            self.enable_segmented_processing = self.enable_segmented_processing_checkbox.isChecked()
            # ä¿å­˜é…ç½®
            self.config_manager.update_config(enable_segmented_processing=self.enable_segmented_processing)
    
    def auto_save_config(self):
        """è‡ªåŠ¨ä¿å­˜é…ç½®"""
        # å¦‚æœæ­£åœ¨åŠ è½½é…ç½®ï¼Œä¸æ‰§è¡Œè‡ªåŠ¨ä¿å­˜
        if hasattr(self, '_loading_config') and self._loading_config:
            return
        self.save_config_from_ui()
    
    def create_action_feedback_group(self) -> QGroupBox:
        """åˆ›å»ºæ‰§è¡Œä¸åé¦ˆåŒº"""
        group = QGroupBox("æ‰§è¡Œä¸åé¦ˆ")
        layout = QVBoxLayout(group)
        layout.setSpacing(15)
        
        # ç”ŸæˆæŒ‰é’®
        # ç”ŸæˆæŒ‰é’®å’Œé‡ç½®é…ç½®æŒ‰é’®
        button_layout = QHBoxLayout()
        
        self.generate_btn = QPushButton("ç”Ÿæˆè§†é¢‘")
        self.generate_btn.setMinimumHeight(50)
        self.generate_btn.clicked.connect(self.generate_video)
        
        self.reset_config_btn = QPushButton("é‡ç½®é…ç½®")
        self.reset_config_btn.setMinimumHeight(50)
        self.reset_config_btn.clicked.connect(self.reset_config)
        self.reset_config_btn.setStyleSheet("""
            QPushButton {
                background-color: #dc3545;
                color: white;
                border: none;
                border-radius: 4px;
                font-weight: bold;
            }
            QPushButton:hover {
                background-color: #c82333;
            }
        """)
        
        button_layout.addWidget(self.generate_btn)
        button_layout.addWidget(self.reset_config_btn)
        layout.addLayout(button_layout)

        # æ€§èƒ½/å¯¼å‡ºè®¾ç½®
        perf_layout = QHBoxLayout()
        fps_label = QLabel("FPS:")
        self.fps_spin = QDoubleSpinBox()
        self.fps_spin.setRange(12, 60)
        self.fps_spin.setDecimals(0)
        self.fps_spin.setValue(24)
        preset_label = QLabel("Preset:")
        self.preset_combo = QComboBox()
        self.preset_combo.addItems(["ultrafast", "superfast", "veryfast", "faster", "fast", "medium"])  # ä»…åŠ é€Ÿé¢„è®¾
        self.preset_combo.setCurrentText("ultrafast")
        crf_label = QLabel("CRF:")
        self.crf_spin = QDoubleSpinBox()
        self.crf_spin.setRange(15, 35)
        self.crf_spin.setDecimals(0)
        self.crf_spin.setValue(23)
        threads_label = QLabel("Threads:")
        self.threads_spin = QDoubleSpinBox()
        self.threads_spin.setRange(1, max(1, (os.cpu_count() or 2)))
        self.threads_spin.setDecimals(0)
        self.threads_spin.setValue(max(1, (os.cpu_count() or 2) - 1))

        perf_layout.addWidget(fps_label)
        perf_layout.addWidget(self.fps_spin)
        perf_layout.addSpacing(10)
        perf_layout.addWidget(preset_label)
        perf_layout.addWidget(self.preset_combo)
        perf_layout.addSpacing(10)
        perf_layout.addWidget(crf_label)
        perf_layout.addWidget(self.crf_spin)
        perf_layout.addSpacing(10)
        perf_layout.addWidget(threads_label)
        perf_layout.addWidget(self.threads_spin)
        layout.addLayout(perf_layout)
        
        # è¿›åº¦æ¡
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        layout.addWidget(self.progress_bar)
        
        # çŠ¶æ€æ ‡ç­¾
        self.status_label = QLabel("å‡†å¤‡å°±ç»ª")
        self.status_label.setAlignment(Qt.AlignCenter)
        self.status_label.setStyleSheet("color: #666; font-style: italic;")
        layout.addWidget(self.status_label)
        
        # è¿æ¥æ€§èƒ½è®¾ç½®æ§ä»¶çš„ä¿¡å·åˆ°è‡ªåŠ¨ä¿å­˜
        self.connect_performance_signals()
        
        return group
    
    def connect_performance_signals(self):
        """è¿æ¥æ€§èƒ½è®¾ç½®æ§ä»¶çš„ä¿¡å·åˆ°è‡ªåŠ¨ä¿å­˜"""
        # æ€§èƒ½/å¯¼å‡ºè®¾ç½®
        self.fps_spin.valueChanged.connect(self.auto_save_config)
        self.preset_combo.currentTextChanged.connect(self.auto_save_config)
        self.crf_spin.valueChanged.connect(self.auto_save_config)
        self.threads_spin.valueChanged.connect(self.auto_save_config)
    
    def create_log_panel(self) -> QGroupBox:
        """åˆ›å»ºæ—¥å¿—é¢æ¿"""
        group = QGroupBox("å¤„ç†æ—¥å¿—")
        layout = QVBoxLayout(group)
        layout.setSpacing(10)
        
        # æ—¥å¿—æ–‡æœ¬åŒºåŸŸ
        self.log_text = QTextEdit()
        self.log_text.setReadOnly(True)
        self.log_text.setFont(QFont("Consolas", 9))
        self.log_text.setStyleSheet("""
            QTextEdit {
                background-color: #1e1e1e;
                color: #ffffff;
                border: 1px solid #555;
                border-radius: 5px;
                padding: 10px;
            }
        """)
        
        # æ¸…ç©ºæ—¥å¿—æŒ‰é’®
        clear_btn = QPushButton("æ¸…ç©ºæ—¥å¿—")
        clear_btn.clicked.connect(self.clear_log)
        clear_btn.setStyleSheet("""
            QPushButton {
                background-color: #6c757d;
                color: white;
                border: none;
                padding: 5px 15px;
                border-radius: 3px;
                font-size: 12px;
            }
            QPushButton:hover {
                background-color: #5a6268;
            }
        """)
        
        layout.addWidget(self.log_text)
        layout.addWidget(clear_btn)
        
        return group
    
    def clear_log(self):
        """æ¸…ç©ºæ—¥å¿—"""
        self.log_text.clear()
        self.log_text.append("æ—¥å¿—å·²æ¸…ç©º")
    
    def add_log_message(self, message: str):
        """æ·»åŠ æ—¥å¿—æ¶ˆæ¯"""
        self.log_text.append(message)
        # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
        scrollbar = self.log_text.verticalScrollBar()
        scrollbar.setValue(scrollbar.maximum())
    
    def setup_styles(self):
        """è®¾ç½®æ ·å¼"""
        self.setStyleSheet("""
            QMainWindow {
                background-color: #f5f5f5;
            }
            QGroupBox {
                font-weight: bold;
                border: 2px solid #cccccc;
                border-radius: 8px;
                margin-top: 10px;
                padding-top: 10px;
            }
            QGroupBox::title {
                subcontrol-origin: margin;
                left: 10px;
                padding: 0 5px 0 5px;
            }
            QPushButton {
                background-color: #0078d4;
                color: white;
                border: none;
                padding: 10px 20px;
                border-radius: 5px;
                font-weight: bold;
                min-height: 20px;
            }
            QPushButton:hover {
                background-color: #106ebe;
            }
            QPushButton:pressed {
                background-color: #005a9e;
            }
            QPushButton:disabled {
                background-color: #cccccc;
                color: #666666;
            }
            QDoubleSpinBox {
                padding: 5px;
                border: 1px solid #cccccc;
                border-radius: 3px;
                min-width: 100px;
            }
            QComboBox {
                padding: 5px;
                border: 1px solid #cccccc;
                border-radius: 3px;
                min-width: 150px;
            }
            QProgressBar {
                border: 1px solid #cccccc;
                border-radius: 5px;
                text-align: center;
            }
            QProgressBar::chunk {
                background-color: #0078d4;
                border-radius: 4px;
            }
        """)
    
    def select_image_folder(self):
        """é€‰æ‹©å›¾ç‰‡æ–‡ä»¶å¤¹"""
        folder_path = QFileDialog.getExistingDirectory(
            self, 
            "é€‰æ‹©åŒ…å«å›¾ç‰‡çš„æ–‡ä»¶å¤¹"
        )
        
        if folder_path:
            self.selected_image_folder = folder_path
            self.image_folder_label.setText(f"å·²é€‰æ‹©: {os.path.basename(folder_path)}")
            self.image_folder_label.setStyleSheet("color: #333; font-style: normal;")
            
            # è‡ªåŠ¨ä¿å­˜é…ç½®
            self.config_manager.update_config(image_folder=folder_path)
    
    def select_audio_file(self):
        """é€‰æ‹©éŸ³é¢‘æ–‡ä»¶"""
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            "é€‰æ‹©éŸ³é¢‘æ–‡ä»¶",
            "",
            "éŸ³é¢‘æ–‡ä»¶ (*.mp3 *.wav *.flac *.aac *.ogg *.m4a *.wma);;æ‰€æœ‰æ–‡ä»¶ (*)"
        )
        
        if file_path:
            self.selected_audio_file = file_path
            file_name = os.path.basename(file_path)
            self.audio_file_label.setText(f"å·²é€‰æ‹©: {file_name}")
            self.audio_file_label.setStyleSheet("color: #333; font-style: normal;")
            
            # è‡ªåŠ¨ä¿å­˜é…ç½®
            self.config_manager.update_config(audio_file=file_path)
    
    def select_audio_folder(self):
        """é€‰æ‹©éŸ³é¢‘æ–‡ä»¶å¤¹"""
        folder_path = QFileDialog.getExistingDirectory(
            self, 
            "é€‰æ‹©éŸ³é¢‘æ–‡ä»¶å¤¹"
        )
        
        if folder_path:
            self.selected_audio_folder = folder_path
            self.audio_folder_label.setText(f"å·²é€‰æ‹©: {os.path.basename(folder_path)}")
            self.audio_folder_label.setStyleSheet("color: #333; font-style: normal;")
            
            # è‡ªåŠ¨ä¿å­˜é…ç½®
            self.config_manager.update_config(audio_folder=folder_path)
    
    def set_processing_mode(self, mode: str):
        """è®¾ç½®å¤„ç†æ¨¡å¼"""
        self.processing_mode = mode
        
        # æ›´æ–°æŒ‰é’®çŠ¶æ€
        if mode == "single":
            self.single_mode_btn.setChecked(True)
            self.batch_mode_btn.setChecked(False)
        else:  # batch
            self.single_mode_btn.setChecked(False)
            self.batch_mode_btn.setChecked(True)
        
        # ä¿å­˜é…ç½®
        self.config_manager.update_config(processing_mode=mode)
    
    def select_video_clip_folder(self):
        """é€‰æ‹©è§†é¢‘ç‰‡æ®µæ–‡ä»¶å¤¹"""
        folder_path = QFileDialog.getExistingDirectory(
            self, 
            "é€‰æ‹©è§†é¢‘ç‰‡æ®µæ–‡ä»¶å¤¹"
        )
        
        if folder_path:
            self.selected_video_clip_folder = folder_path
            self.video_clip_folder_label.setText(f"å·²é€‰æ‹©: {os.path.basename(folder_path)}")
            self.video_clip_folder_label.setStyleSheet("color: #333; font-style: normal;")
            
            # è‡ªåŠ¨ä¿å­˜é…ç½®
            self.config_manager.update_config(video_clip_folder=folder_path)
    
    def toggle_video_clips(self):
        """åˆ‡æ¢è§†é¢‘ç‰‡æ®µæ’å…¥åŠŸèƒ½"""
        self.enable_video_clips = self.enable_video_clips_checkbox.isChecked()
        self.video_clip_count_spin.setEnabled(self.enable_video_clips)
        
        # æ›´æ–°æŒ‰é’®æ ·å¼
        if self.enable_video_clips:
            self.enable_video_clips_checkbox.setStyleSheet("""
                QPushButton {
                    background-color: #28a745;
                    color: white;
                    border: none;
                    padding: 8px 16px;
                    border-radius: 4px;
                    font-weight: bold;
                }
                QPushButton:hover {
                    background-color: #218838;
                }
            """)
        else:
            self.enable_video_clips_checkbox.setStyleSheet("""
                QPushButton {
                    background-color: #6c757d;
                    color: white;
                    border: none;
                    padding: 8px 16px;
                    border-radius: 4px;
                    font-weight: bold;
                }
                QPushButton:hover {
                    background-color: #5a6268;
                }
            """)
        
        # ä¿å­˜é…ç½®
        self.config_manager.update_config(enable_video_clips=self.enable_video_clips)
    
    def on_scale_mode_changed(self, mode_text: str):
        """å¤„ç†ç¼©æ”¾æ¨¡å¼å˜åŒ–"""
        if "è£å‰ªæ¨¡å¼" in mode_text:
            self.video_clip_scale_mode = "crop"
        elif "é€‚åº”æ¨¡å¼" in mode_text:
            self.video_clip_scale_mode = "fit"
        elif "æ‹‰ä¼¸æ¨¡å¼" in mode_text:
            self.video_clip_scale_mode = "stretch"
        
        # ä¿å­˜é…ç½®
        self.config_manager.update_config(video_clip_scale_mode=self.video_clip_scale_mode)
    
    def select_processed_folder(self):
        """é€‰æ‹©å·²å¤„ç†å›¾ç‰‡æ–‡ä»¶å¤¹"""
        folder_path = QFileDialog.getExistingDirectory(
            self, 
            "é€‰æ‹©å·²å¤„ç†å›¾ç‰‡æ–‡ä»¶å¤¹"
        )
        
        if folder_path:
            self.selected_processed_folder = folder_path
            self.processed_folder_label.setText(f"å·²é€‰æ‹©: {os.path.basename(folder_path)}")
            self.processed_folder_label.setStyleSheet("color: #333; font-style: normal;")
            
            # è‡ªåŠ¨ä¿å­˜é…ç½®
            self.config_manager.update_config(processed_folder=folder_path)
    
    def select_output_folder(self):
        """é€‰æ‹©è¾“å‡ºè§†é¢‘æ–‡ä»¶å¤¹"""
        folder_path = QFileDialog.getExistingDirectory(
            self, 
            "é€‰æ‹©è¾“å‡ºè§†é¢‘æ–‡ä»¶å¤¹"
        )
        
        if folder_path:
            self.selected_output_folder = folder_path
            self.output_folder_label.setText(f"å·²é€‰æ‹©: {os.path.basename(folder_path)}")
            self.output_folder_label.setStyleSheet("color: #333; font-style: normal;")
            
            # è‡ªåŠ¨ä¿å­˜é…ç½®
            self.config_manager.update_config(output_folder=folder_path)
    
    def select_processed_video_folder(self):
        """é€‰æ‹©å·²å¤„ç†è§†é¢‘ç‰‡æ®µæ–‡ä»¶å¤¹"""
        folder_path = QFileDialog.getExistingDirectory(
            self, 
            "é€‰æ‹©å·²å¤„ç†è§†é¢‘ç‰‡æ®µæ–‡ä»¶å¤¹"
        )
        
        if folder_path:
            self.selected_processed_video_folder = folder_path
            self.processed_video_folder_label.setText(f"å·²é€‰æ‹©: {os.path.basename(folder_path)}")
            self.processed_video_folder_label.setStyleSheet("color: #333; font-style: normal;")
            
            # è‡ªåŠ¨ä¿å­˜é…ç½®
            self.config_manager.update_config(processed_video_folder=folder_path)
            
    def reset_config(self):
        """é‡ç½®é…ç½®ä¸ºé»˜è®¤å€¼"""
        reply = QMessageBox.question(
            self, 
            "ç¡®è®¤é‡ç½®", 
            "ç¡®å®šè¦é‡ç½®æ‰€æœ‰é…ç½®ä¸ºé»˜è®¤å€¼å—ï¼Ÿ\nè¿™å°†æ¸…é™¤æ‰€æœ‰å·²é€‰æ‹©çš„æ–‡ä»¶å’Œè®¾ç½®ã€‚",
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
        )
        
        if reply == QMessageBox.StandardButton.Yes:
            # é‡ç½®é…ç½®
            self.config_manager.reset_config()
            self.config = self.config_manager.load_config()
            
            # é‡ç½®UI
            self.selected_image_folder = None
            self.selected_audio_file = None
            self.selected_audio_folder = None
            self.selected_processed_folder = None
            self.selected_output_folder = None
            self.selected_video_clip_folder = None
            self.selected_processed_video_folder = None
            self.processing_mode = "single"
            self.enable_video_clips = False
            self.video_clip_count = 3
            self.video_clip_scale_mode = "crop"
            
            self.image_folder_label.setText("æœªé€‰æ‹©æ–‡ä»¶å¤¹")
            self.image_folder_label.setStyleSheet("color: #999; font-style: italic;")
            self.audio_file_label.setText("æœªé€‰æ‹©éŸ³é¢‘æ–‡ä»¶")
            self.audio_file_label.setStyleSheet("color: #999; font-style: italic;")
            self.audio_folder_label.setText("æœªé€‰æ‹©éŸ³é¢‘æ–‡ä»¶å¤¹")
            self.audio_folder_label.setStyleSheet("color: #999; font-style: italic;")
            self.processed_folder_label.setText("æœªé€‰æ‹©å·²å¤„ç†æ–‡ä»¶å¤¹")
            self.processed_folder_label.setStyleSheet("color: #999; font-style: italic;")
            self.output_folder_label.setText("æœªé€‰æ‹©è¾“å‡ºæ–‡ä»¶å¤¹")
            self.output_folder_label.setStyleSheet("color: #999; font-style: italic;")
            self.video_clip_folder_label.setText("æœªé€‰æ‹©è§†é¢‘ç‰‡æ®µæ–‡ä»¶å¤¹")
            self.video_clip_folder_label.setStyleSheet("color: #999; font-style: italic;")
            self.processed_video_folder_label.setText("æœªé€‰æ‹©å·²å¤„ç†è§†é¢‘ç‰‡æ®µæ–‡ä»¶å¤¹")
            self.processed_video_folder_label.setStyleSheet("color: #999; font-style: italic;")
            
            # é‡ç½®å¤„ç†æ¨¡å¼æŒ‰é’®
            self.single_mode_btn.setChecked(True)
            self.batch_mode_btn.setChecked(False)
            
            # é‡ç½®è§†é¢‘ç‰‡æ®µè®¾ç½®
            self.enable_video_clips_checkbox.setChecked(False)
            self.video_clip_count_spin.setEnabled(False)
            self.video_clip_count_spin.setValue(3)
            self.video_clip_scale_combo.setCurrentText("è£å‰ªæ¨¡å¼ (ä¿æŒæ¯”ä¾‹)")
            if hasattr(self, 'enable_segmented_processing_checkbox'):
                self.enable_segmented_processing_checkbox.setChecked(True)
            self.enable_segmented_processing = True
            
            # é‡æ–°åŠ è½½é…ç½®åˆ°UI
            self.load_config_to_ui()
            
            QMessageBox.information(self, "é‡ç½®å®Œæˆ", "é…ç½®å·²é‡ç½®ä¸ºé»˜è®¤å€¼")
    
    def generate_video(self):
        """ç”Ÿæˆè§†é¢‘"""
        # è¾“å…¥éªŒè¯
        if not self.selected_image_folder:
            QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©å›¾ç‰‡æ–‡ä»¶å¤¹")
            return
        
        if self.processing_mode == "single":
            if not self.selected_audio_file:
                QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©éŸ³é¢‘æ–‡ä»¶")
                return
            self.process_single_audio()
        else:  # batch mode
            if not self.selected_audio_folder:
                QMessageBox.warning(self, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©éŸ³é¢‘æ–‡ä»¶å¤¹")
                return
            self.process_batch_audio()
    
    def process_single_audio(self):
        """å¤„ç†å•ä¸ªéŸ³é¢‘æ–‡ä»¶"""
        # ç”Ÿæˆé»˜è®¤æ–‡ä»¶åï¼ˆä½¿ç”¨éŸ³é¢‘æ–‡ä»¶åï¼‰
        audio_basename = os.path.splitext(os.path.basename(self.selected_audio_file))[0]
        default_filename = f"{audio_basename}.mp4"
        
        if self.selected_output_folder:
            default_path = os.path.join(self.selected_output_folder, default_filename)
        else:
            default_path = default_filename
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if os.path.exists(default_path):
            # æ–‡ä»¶å·²å­˜åœ¨ï¼Œå¼¹çª—ç¡®è®¤
            reply = QMessageBox.question(
                self,
                "æ–‡ä»¶å·²å­˜åœ¨",
                f"æ–‡ä»¶ '{default_filename}' å·²å­˜åœ¨ï¼Œæ˜¯å¦è¦†ç›–ï¼Ÿ\n\n"
                f"è·¯å¾„: {default_path}",
                QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No,
                QMessageBox.StandardButton.No
            )
            
            if reply == QMessageBox.StandardButton.No:
                # ç”¨æˆ·é€‰æ‹©ä¸è¦†ç›–ï¼Œæ‰“å¼€æ–‡ä»¶å¯¹è¯æ¡†è®©ç”¨æˆ·é€‰æ‹©å…¶ä»–ä½ç½®æˆ–æ–‡ä»¶å
                output_path, _ = QFileDialog.getSaveFileName(
                    self,
                    "ä¿å­˜è§†é¢‘æ–‡ä»¶",
                    default_path,
                    "MP4è§†é¢‘æ–‡ä»¶ (*.mp4);;æ‰€æœ‰æ–‡ä»¶ (*)"
                )
            else:
                # ç”¨æˆ·é€‰æ‹©è¦†ç›–ï¼Œç›´æ¥ä½¿ç”¨é»˜è®¤è·¯å¾„
                output_path = default_path
        else:
            # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥ä½¿ç”¨é»˜è®¤è·¯å¾„
            output_path = default_path
        
        if not output_path:
            return
        
        # ä¿å­˜è¾“å‡ºæ–‡ä»¶å¤¹åˆ°é…ç½®
        output_folder = os.path.dirname(output_path)
        self.selected_output_folder = output_folder
        self.output_folder_label.setText(f"å·²é€‰æ‹©: {os.path.basename(output_folder)}")
        self.output_folder_label.setStyleSheet("color: #333; font-style: normal;")
        self.config_manager.update_config(output_folder=output_folder)
        
        # å¼€å§‹å¤„ç†å•ä¸ªéŸ³é¢‘
        self.start_video_generation(self.selected_audio_file, output_path)
    
    def process_batch_audio(self):
        """å¤„ç†æ‰¹é‡éŸ³é¢‘æ–‡ä»¶"""
        # è·å–éŸ³é¢‘æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶
        audio_extensions = {'.mp3', '.wav', '.flac', '.aac', '.ogg', '.m4a', '.wma'}
        audio_files = []
        
        for file in os.listdir(self.selected_audio_folder):
            if any(file.lower().endswith(ext) for ext in audio_extensions):
                audio_files.append(os.path.join(self.selected_audio_folder, file))
        
        if not audio_files:
            QMessageBox.warning(self, "è­¦å‘Š", "éŸ³é¢‘æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°æ”¯æŒçš„éŸ³é¢‘æ–‡ä»¶")
            return
        
        # æŒ‰æ–‡ä»¶åæ’åº
        audio_files.sort()
        
        # ç¡®è®¤æ‰¹é‡å¤„ç†
        reply = QMessageBox.question(
            self,
            "ç¡®è®¤æ‰¹é‡å¤„ç†",
            f"æ‰¾åˆ° {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶ï¼Œæ˜¯å¦å¼€å§‹æ‰¹é‡å¤„ç†ï¼Ÿ\n\n"
            f"éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨:\n" + "\n".join([os.path.basename(f) for f in audio_files[:5]]) + 
            (f"\n... è¿˜æœ‰ {len(audio_files) - 5} ä¸ªæ–‡ä»¶" if len(audio_files) > 5 else ""),
            QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
        )
        
        if reply != QMessageBox.StandardButton.Yes:
            return
        
        # å¼€å§‹æ‰¹é‡å¤„ç†
        self.start_batch_processing(audio_files)
    
    def start_batch_processing(self, audio_files):
        """å¼€å§‹æ‰¹é‡å¤„ç†"""
        self.batch_audio_files = audio_files
        self.current_batch_index = 0
        self.process_next_batch_audio()
    
    def process_next_batch_audio(self):
        """å¤„ç†ä¸‹ä¸€ä¸ªæ‰¹é‡éŸ³é¢‘æ–‡ä»¶"""
        if self.current_batch_index >= len(self.batch_audio_files):
            # æ‰¹é‡å¤„ç†å®Œæˆ
            self.add_log_message("=== æ‰¹é‡å¤„ç†å®Œæˆ ===")
            self.status_label.setText("æ‰¹é‡å¤„ç†å®Œæˆï¼")
            self.status_label.setStyleSheet("color: #28a745; font-weight: bold;")
            QMessageBox.information(self, "æ‰¹é‡å¤„ç†å®Œæˆ", f"å·²æˆåŠŸå¤„ç† {len(self.batch_audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
            
            # æ¸…ç†å·¥ä½œçº¿ç¨‹
            if self.worker_thread:
                self.worker_thread.stop()
                self.worker_thread.deleteLater()
                self.worker_thread = None
            
            # æ¸…ç†æ‰¹é‡å¤„ç†ç›¸å…³å±æ€§
            if hasattr(self, 'batch_audio_files'):
                delattr(self, 'batch_audio_files')
            if hasattr(self, 'current_batch_index'):
                delattr(self, 'current_batch_index')
            return
        
        current_audio = self.batch_audio_files[self.current_batch_index]
        audio_basename = os.path.splitext(os.path.basename(current_audio))[0]
        default_filename = f"{audio_basename}.mp4"
        
        if self.selected_output_folder:
            output_path = os.path.join(self.selected_output_folder, default_filename)
        else:
            output_path = default_filename
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ åºå·
        counter = 1
        original_output_path = output_path
        while os.path.exists(output_path):
            name, ext = os.path.splitext(original_output_path)
            output_path = f"{name}_{counter}{ext}"
            counter += 1
        
        self.add_log_message(f"å¼€å§‹å¤„ç†ç¬¬ {self.current_batch_index + 1}/{len(self.batch_audio_files)} ä¸ªéŸ³é¢‘: {os.path.basename(current_audio)}")
        self.add_log_message(f"å‰©ä½™å¾…å¤„ç†: {len(self.batch_audio_files) - self.current_batch_index - 1} ä¸ªéŸ³é¢‘æ–‡ä»¶")
        
        # å¼€å§‹å¤„ç†å½“å‰éŸ³é¢‘
        self.start_video_generation(current_audio, output_path)
    
    def start_video_generation(self, audio_file, output_path):
        """å¼€å§‹è§†é¢‘ç”Ÿæˆ"""
        # è·å–å‚æ•°
        # å–æ—¶é•¿èŒƒå›´å¹¶ç¡®ä¿ min<=max
        dur_min = float(self.duration_min_spin.value())
        dur_max = float(self.duration_max_spin.value())
        if dur_min > dur_max:
            dur_min, dur_max = dur_max, dur_min
        animation_effect = self.effect_combo.currentText()
        animation_intensity = self.intensity_spinbox.value()
        # è§£æåˆ†è¾¨ç‡
        selected_res = self.resolution_combo.currentText()
        if selected_res.startswith("Custom"):
            target_resolution = (int(self.custom_width_spin.value()), int(self.custom_height_spin.value()))
        else:
            try:
                wh = selected_res.split(" ")[0]
                w, h = wh.split("x")
                target_resolution = (int(w), int(h))
            except Exception:
                target_resolution = (1920, 1080)
        
        # ç¦ç”¨ç”ŸæˆæŒ‰é’®
        self.generate_btn.setEnabled(False)
        self.generate_btn.setText("ç”Ÿæˆä¸­...")
        
        # æ˜¾ç¤ºè¿›åº¦æ¡
        self.progress_bar.setVisible(True)
        self.progress_bar.setValue(0)
        
        # åˆ›å»ºå¹¶å¯åŠ¨å·¥ä½œçº¿ç¨‹
        self.worker_thread = VideoGenerationWorker(
            self.selected_image_folder,
            audio_file,
            (dur_min, dur_max),
            animation_effect,
            output_path,
            animation_intensity,
            target_resolution,
            int(self.fps_spin.value()),
            self.preset_combo.currentText(),
            int(self.crf_spin.value()),
            int(self.threads_spin.value()),
            self.selected_processed_folder,
            self.selected_video_clip_folder,
            self.enable_video_clips,
            int(self.video_clip_count_spin.value()),
            self.video_clip_scale_mode,
            self.selected_processed_video_folder,
            self.enable_segmented_processing
        )
        
        # è¿æ¥ä¿¡å·
        self.worker_thread.progress_updated.connect(self.progress_bar.setValue)
        self.worker_thread.status_updated.connect(self.status_label.setText)
        self.worker_thread.log_updated.connect(self.add_log_message)
        self.worker_thread.generation_finished.connect(self.on_generation_finished)
        
        # å¯åŠ¨çº¿ç¨‹
        self.worker_thread.start()
    
    def on_generation_finished(self, success: bool, message: str):
        """å¤„ç†ç”Ÿæˆå®Œæˆ"""
        # æ¢å¤UIçŠ¶æ€
        self.generate_btn.setEnabled(True)
        self.generate_btn.setText("ç”Ÿæˆè§†é¢‘")
        self.progress_bar.setVisible(False)
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ‰¹é‡å¤„ç†æ¨¡å¼
        is_batch_mode = hasattr(self, 'batch_audio_files') and hasattr(self, 'current_batch_index')
        
        if success:
            self.status_label.setText("ç”Ÿæˆå®Œæˆï¼")
            self.status_label.setStyleSheet("color: #28a745; font-weight: bold;")
            
            if is_batch_mode:
                # æ‰¹é‡å¤„ç†æ¨¡å¼ï¼Œå¤„ç†ä¸‹ä¸€ä¸ªæ–‡ä»¶
                self.add_log_message(f"âœ“ ç¬¬ {self.current_batch_index + 1} ä¸ªéŸ³é¢‘å¤„ç†å®Œæˆ")
                self.current_batch_index += 1
                self.process_next_batch_audio()
            else:
                # å•ä¸ªå¤„ç†æ¨¡å¼
                QMessageBox.information(self, "æˆåŠŸ", message)
        else:
            self.status_label.setText("ç”Ÿæˆå¤±è´¥")
            self.status_label.setStyleSheet("color: #dc3545; font-weight: bold;")
            
            if is_batch_mode:
                # æ‰¹é‡å¤„ç†æ¨¡å¼ï¼Œè¯¢é—®æ˜¯å¦ç»§ç»­
                reply = QMessageBox.question(
                    self,
                    "æ‰¹é‡å¤„ç†é”™è¯¯",
                    f"å¤„ç†ç¬¬ {self.current_batch_index + 1} ä¸ªéŸ³é¢‘æ–‡ä»¶æ—¶å‡ºé”™ï¼š\n{message}\n\næ˜¯å¦ç»§ç»­å¤„ç†å‰©ä½™æ–‡ä»¶ï¼Ÿ",
                    QMessageBox.StandardButton.Yes | QMessageBox.StandardButton.No
                )
                
                if reply == QMessageBox.StandardButton.Yes:
                    self.add_log_message(f"âœ— ç¬¬ {self.current_batch_index + 1} ä¸ªéŸ³é¢‘å¤„ç†å¤±è´¥ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ª")
                    self.current_batch_index += 1
                    self.process_next_batch_audio()
                else:
                    # åœæ­¢æ‰¹é‡å¤„ç†
                    self.add_log_message("ç”¨æˆ·é€‰æ‹©åœæ­¢æ‰¹é‡å¤„ç†")
                    self.status_label.setText("æ‰¹é‡å¤„ç†å·²åœæ­¢")
                    
                    # æ¸…ç†å·¥ä½œçº¿ç¨‹
                    if self.worker_thread:
                        self.worker_thread.stop()
                        self.worker_thread.deleteLater()
                        self.worker_thread = None
                    
                    # æ¸…ç†æ‰¹é‡å¤„ç†ç›¸å…³å±æ€§
                    if hasattr(self, 'batch_audio_files'):
                        delattr(self, 'batch_audio_files')
                    if hasattr(self, 'current_batch_index'):
                        delattr(self, 'current_batch_index')
            else:
                # å•ä¸ªå¤„ç†æ¨¡å¼
                QMessageBox.critical(self, "é”™è¯¯", message)
        
        # æ¸…ç†å·¥ä½œçº¿ç¨‹ï¼ˆåªåœ¨éæ‰¹é‡å¤„ç†æ¨¡å¼æˆ–æ‰¹é‡å¤„ç†å®Œæˆæ—¶æ¸…ç†ï¼‰
        if not is_batch_mode:
            if self.worker_thread:
                self.worker_thread.stop()
                self.worker_thread.deleteLater()
                self.worker_thread = None


def main():
    app = QApplication(sys.argv)
    app.setStyle('Fusion')
    
    window = MainWindow()
    window.show()
    
    sys.exit(app.exec())


if __name__ == "__main__":
    main()